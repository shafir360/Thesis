{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"3BYAszwthl-5"},"outputs":[],"source":["!pip install tweepy==4.1\n","!pip install configparser\n","!pip install pandas\n","#!pip install tweepy[async]\n","#!pip install git+https://github.com/tweepy/tweepy.git\n","import tweepy\n","import pandas as pd\n","import numpy as np\n","import requests\n","import os\n","import re\n","import csv\n","import datetime"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"24ihDJwbvAba"},"outputs":[],"source":["consumer_key = \"fHmtSQIia88vkU2VJz7pqaWVZ\"\n","consumer_secret = \"z6snlsYQ6X19S2hV6ySmxPWtPm2D56iq5XiB59ak1FzX5Q13a3\"\n","access_token = \"1496943539619606532-kNiBnYAPlvX5PafSiNjNLqlDBhEd12\"\n","access_token_secret = \"aVWNHSgDSJ30xD4Y3Q8k7HtpHxI8nXkoghSo4bBwHkGuS\"\n","bearer_token = \"AAAAAAAAAAAAAAAAAAAAAARsZgEAAAAAI6SnEitNtciJphrwSNvN6RGHp98%3DQDhvsy78GosA3BNseXN1im7NdYufSlNopoGf14iQiD5tD5NFsa\"\n","client_secret = \"vyCf0Oxx1dpxw8XTGphrVqZQkJ72yEA2mPSai5TSBjww2lASR6\"\n","\n","\n","\n","#consumer_key = fHmtSQIia88vkU2VJz7pqaWVZ\n","#consumer_secret = z6snlsYQ6X19S2hV6ySmxPWtPm2D56iq5XiB59ak1FzX5Q13a3\n","#access_token = 1496943539619606532-kNiBnYAPlvX5PafSiNjNLqlDBhEd12\n","#access_token_secret = aVWNHSgDSJ30xD4Y3Q8k7HtpHxI8nXkoghSo4bBwHkGuS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ErCEF9qRwNq6"},"outputs":[],"source":["client = tweepy.Client(bearer_token = bearer_token, consumer_key = consumer_key , consumer_secret = consumer_secret ,access_token = access_token,access_token_secret = access_token_secret, wait_on_rate_limit = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fm5VhAziy1aX"},"outputs":[],"source":["import datetime\n","#q = \"#crudeoil OR crude oil OR opec OR #opec -guiding -guided lang:en -is:retweet -has:links -filter:retweets\"\n","q = \"btc OR Bitcoin OR bitcoin OR BTC -#nft -nft -giveaway -guiding -guided lang:en -is:retweet -has:links\"\n","#q = \"dogecoin OR doge -#nft -nft -giveaway -guiding -guided lang:en -is:retweet -has:links\"\n","#q = \"btc\"\n","#file_name = \"tweets.txt\"\n","\n","columns = ['id','time','language','author_id','geo','source','tweet']\n","data = []\n","\n","#auth_handler =tweepy.OAuthHandler(consumer_key=consumer_key, consumer_secret= consumer_secret )\n","#auth_handler.set_access_token(access_token,access_token_secret)\n","#api = tweepy.API(auth_handler, wait_on_rate_limit=True)\n","\n","#tweet_amount = 300000\n","tweet_amount = 499900\n","#data = tweepy.cursor(api.search_tweets, q = q, lang = 'en',).items(tweet_amount)\n","#start_time = datetime.datetime(2010,1,1)\n","\n","for tweet in tweepy.Paginator(client.search_recent_tweets, query = q , max_results=100, tweet_fields=[\"created_at\", \"lang\" , \"author_id\",\"geo\",\"source\" ]).flatten(limit = tweet_amount):\n","  data.append([tweet.id, tweet.created_at,tweet.lang,tweet.author_id, tweet.geo,tweet.source, tweet.text])\n","\n","\n","\n","\n","df = pd.DataFrame(data,columns=columns )\n","print(df.size/7)\n","display(df)\n","#display(data)\n","name = \"tweepy_499900\"\n","df.to_csv(\"/content/drive/MyDrive/fyp/fyp2/tweepy data/\" + name + \".csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MfNXNCeRlhL4"},"outputs":[],"source":["#name = \"tweepy_100\"\n","#df.to_csv(\"/content/drive/MyDrive/fyp/fyp2/tweepy data/\" + name + \".csv\")\n","\n","\n","df_test = pd.read_csv(\"/content/drive/MyDrive/fyp/fyp2/tweepy data/\" + name + \".csv\")\n","display(df_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mxeDUs8BoN7F"},"outputs":[],"source":["df = pd.DataFrame(data,columns=columns )\n","display(df)\n","#display(data)\n","name = \"tweepy_save\"\n","df.to_csv(\"/content/drive/MyDrive/fyp/fyp2/tweepy data/\" + name + \".csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"vtsGmQTwcXXl"},"outputs":[],"source":["]auth_handler =tweepy.OAuthHandler(consumer_key=consumer_key, consumer_secret= consumer_secret )\n","auth_handler.set_access_token(access_token,access_token_secret)\n","api = tweepy.API(auth_handler, wait_on_rate_limit=True)\n","\n","q = \"Bitcoin OR bitcoin -#nft -nft -giveaway -guiding -guided lang:en -is:retweet -has:links\"\n","columns = ['tweet_id','time','language','geo','source','followers_count','friends_count','user_id','user_listed_count','user_created_at','retweet_count','favorite_count','text']\n","data = []\n","tweet_amount = 1000001\n","\n","#tweet_amount  = 2\n","try:\n","  for tweet in tweepy.Cursor(api.search_tweets, q = q ,lang = 'en', tweet_mode = 'extended').items(limit = tweet_amount):\n","    #print(tweet)\n","    data.append([tweet.id, tweet.created_at,tweet.lang, tweet.geo,tweet.source,tweet.user.followers_count,tweet.user.friends_count,tweet.user.id,tweet.user.listed_count,tweet.user.created_at ,tweet.retweet_count,tweet.favorite_count ,tweet.full_text])\n","  df = pd.DataFrame(data,columns=columns )\n","  name = \"tweepy_1_\" + str(tweet_amount)\n","  df.to_csv(\"/content/drive/MyDrive/fyp/fyp2/tweepy data/\" + name + \".csv\")\n","  print(df.size/13)\n","  display(df)\n","except Exception as e:\n","  print(\"Function errored out!\", e)\n","  print(\"Retrying ... \")\n","  df = pd.DataFrame(data,columns=columns )\n","  name = \"tweepy_1_\" + str(tweet_amount)\n","  df.to_csv(\"/content/drive/MyDrive/fyp/fyp2/tweepy data/\" + name + \".csv\")\n","  print(df.size/13)\n","  display(df)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Skr3Na0Q7crh"},"outputs":[],"source":["df = pd.DataFrame(data,columns=columns )\n","name = \"tweepy_\" + \"test\"\n","#df.to_csv(\"/content/drive/MyDrive/fyp/fyp2/tweepy data/\" + name + \".csv\")\n","print(df.size/13)\n","display(df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2dbPjDHUUhMz"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hnb21VTkxKjq"},"outputs":[],"source":["\"\"\"Extract nested values from a JSON tree.\"\"\"\n","\n","\n","def json_extract(obj, key):\n","    \"\"\"Recursively fetch values from nested JSON.\"\"\"\n","    arr = []\n","\n","    def extract(obj, arr, key):\n","        \"\"\"Recursively search for values of key in JSON tree.\"\"\"\n","        if isinstance(obj, dict):\n","            for k, v in obj.items():\n","                if isinstance(v, (dict, list)):\n","                    extract(v, arr, key)\n","                elif k == key:\n","                    arr.append(v)\n","        elif isinstance(obj, list):\n","            for item in obj:\n","                extract(item, arr, key)\n","        return arr\n","\n","    values = extract(obj, arr, key)\n","    return values\n","\n","\n","#from extract import json_extract\n","\n","# Find every instance of `name` in a Python dictionary.\n","names = json_extract(tweet, 'user')\n","print(tweet)\n","\n","#print(getKeys(tweet))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m6Pyl--8N-cn"},"outputs":[],"source":["df = pd.DataFrame(data,columns=columns )\n","print(df.size/7)\n","display(df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mTmYUhojDdaE"},"outputs":[],"source":["#print(df)\n","print(df.size)\n","df = pd.DataFrame(data,columns=columns )\n","df.to_csv('/content/drive/MyDrive/fyp/fyp2/tweets_bitcoin_300000_.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TjRbQxamUxwv"},"outputs":[],"source":["df = pd.DataFrame(data,columns=columns )\n","df.to_csv('/content/drive/MyDrive/fyp/fyp2/tweets_bitcoin_big_2.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"15QoMfJJMJjQ"},"outputs":[],"source":["#data1 = pd.read_csv(\"/content/drive/MyDrive/fyp/tweets_crude6.csv\")\n","#data2 = pd.read_csv(\"/content/drive/MyDrive/fyp/tweets_crude6_2.csv\")\n","\n","\n","\n","data = pd.concat([data2, data1])\n","\n","print(data.size)\n","#display(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L0qO6vPyTdG9"},"outputs":[],"source":["##test\n","encoding_used = \"ISO-8859-1\"\n","##\n","data_load = pd.read_csv(\"/content/drive/MyDrive/fyp/training.1600000.processed.noemoticon.csv\",encoding = encoding_used)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l3lSKr31UYrj"},"outputs":[],"source":["#test cont\n","data = data_load\n","\n","data = data.set_axis(['polarity', 'id', 'date', 'flag', 'user' , 'tweet'], axis=1)\n","\n","def filter(data):\n","  df = data\n","  df = df[df[\"tweet\"].str.contains(\" crypto | cryptocurrency | bitcoin | btc \")==True]\n","  return df\n","def clean(text):\n","  text = re.sub(r'@[A-Za-z0-9:]+', '',text) #removes @ mentions\n","  text = re.sub(r'#','',text) #remove #\n","  text = re.sub(r'RT[\\s]+','',text) # remove RT\n","  text = re.sub(r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)', '', text) #removes links\n","  text = re.sub(r'\\s*$','',text) #remove leading and trailing whitespace\n","  text = re.sub(r'^\\s*','',text) #remove leading and leading whitespace\n","  text = re.sub(r'.+:', '',text) #remove username:\n","  return text\n","\n","def clean_data(data):\n","  #data = data[data.language == 'en']\n","  data['tweet'] = data['tweet'].apply(clean)\n","  data.replace(\"\", np.nan, inplace=True) # replace empty string to nan \n","  data.dropna(subset = [\"tweet\"], inplace=True) #remove all rows with nan tweet\n","  return data\n","\n","data = filter(data)\n","clean_data = clean_data(data)\n","display(clean_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S-TsicdoOHqo"},"outputs":[],"source":["def clean(text):\n","  text = re.sub(r'@[A-Za-z0-9:]+', '',text) #removes @ mentions\n","  text = re.sub(r'#','',text) #remove #\n","  text = re.sub(r'RT[\\s]+','',text) # remove RT\n","  text = re.sub(r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)', '', text) #removes links\n","  text = re.sub(r'\\s*$','',text) #remove leading and trailing whitespace\n","  text = re.sub(r'^\\s*','',text) #remove leading and leading whitespace\n","  text = re.sub(r'.+:', '',text) #remove username:\n","  return text\n","\n","def clean_data(data):\n","  data = data[data.language == 'en']\n","  data['tweet'] = data['tweet'].apply(clean)\n","  data.replace(\"\", np.nan, inplace=True) # replace empty string to nan \n","  data.dropna(subset = [\"tweet\"], inplace=True) #remove all rows with nan tweet\n","  return data\n","\n","\n","\n","clean_data = clean_data(data)\n","clean_data.to_csv('/content/drive/MyDrive/fyp/tweets_crude6_clean.csv')\n","display(clean_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6IVnJDJj8sp2"},"outputs":[],"source":["from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.decomposition import LatentDirichletAllocation\n","import random\n","\n","df = pd.read_csv(\"/content/drive/MyDrive/fyp/tweets_crude6_clean.csv\")\n","df = df[['tweet']]\n","df = df.drop_duplicates(subset=['tweet'])\n","#display(df)\n","df.head()\n","\n","\n","cv = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n","dtm = cv.fit_transform(df['tweet'])\n","dtm\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JmWLOUi-GDYe"},"outputs":[],"source":["\n","LDA = LatentDirichletAllocation(n_components=5,random_state=42)\n","LDA.fit(dtm)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cZk1octAGTaU"},"outputs":[],"source":["for index,topic in enumerate(LDA.components_):\n","    print(f'THE TOP 15 WORDS FOR TOPIC #{index}')\n","    print([cv.get_feature_names()[i] for i in topic.argsort()[-15:]])\n","    print('\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ieBAl_vGLO-2"},"outputs":[],"source":["topic_results = LDA.transform(dtm)\n","df['Topic'] = topic_results.argmax(axis=1)\n","display(df)\n","df.to_csv('/content/drive/MyDrive/fyp/tweets_crude6_lda.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oP3CP7SoM5yO"},"outputs":[],"source":["#z = df.drop_duplicates(subset=['tweet'])\n","z = df\n","t = z[df.Topic == 0]\n","display(t)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EDuWPWMzU7JV"},"outputs":[],"source":["!pip install vaderSentiment"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eDuF0qowVC42"},"outputs":[],"source":["from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n","\n","analyser = SentimentIntensityAnalyzer()\n","\n","def sentiment_analyzer_scores(sentence):\n","    score = analyser.polarity_scores(sentence)\n","    #print(\"{:-<40} {}\".format(sentence, str(score)))\n","    return score\n","df = pd.read_csv(\"/content/drive/MyDrive/fyp/tweets_crude6_clean.csv\")\n","\n","score = sentiment_analyzer_scores(\"wow so nice of you\")\n","print(score['pos'])\n","print(score)\n","#display(df)\n","score_negative = []\n","score_neutral = []\n","score_positive = []\n","score_compound = []\n","\n","for tweet in df.tweet:\n","  score = sentiment_analyzer_scores(tweet)\n","  score_negative.append(score['neg'])\n","  score_neutral.append(score['neu'])\n","  score_positive.append(score['pos'])\n","  score_compound.append(score['compound'])\n","\n","df['negative score'] = score_negative\n","df['postive score'] = score_positive\n","df['neutral score'] = score_neutral\n","df['compound score'] = score_compound\n","\n","\n","df = df.drop(['id', 'time' , 'language','author_id' , 'geo', 'source'], axis = 1)\n","display(df)\n","\n","df.to_csv('/content/drive/MyDrive/fyp/tweets_crude6_vader_sentient_analysis.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wMIjAvEnoeGb"},"outputs":[],"source":["import pymc3 as pm\n","import theano as th\n","import seaborn as sns\n","import matplotlib.cm as cm\n","import matplotlib.pyplot as plt\n","from matplotlib.collections import LineCollection\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn import cluster, covariance, manifold\n","\n","df = pd.read_csv(\"/content/drive/MyDrive/fyp/tweets_crude6_clean.csv\")\n","\n","\n","display(df)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HjZILYnG1CuW"},"outputs":[],"source":["display(zf)"]}],"metadata":{"colab":{"background_execution":"on","collapsed_sections":[],"machine_shape":"hm","name":"tweepy_test.ipynb","provenance":[],"mount_file_id":"1raH9ytdvG36ucZq38SCazSXdlx0x38xj","authorship_tag":"ABX9TyPJUTpFJA+xzPbWoo3Hp0tl"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}