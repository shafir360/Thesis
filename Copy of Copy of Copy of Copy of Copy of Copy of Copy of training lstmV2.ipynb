{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DYGAmOFPWXUi","outputId":"166c05e3-1c97-405a-c8ab-ecd41fa364ae"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.6)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.2.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"]}],"source":["num = 7\n","!pip install pandas\n","!pip install transformers\n","!pip install datasets\n","import pandas as pd\n","import numpy as np\n","import requests\n","import os\n","import re\n","import csv\n","import pytz\n","import sklearn\n","from datetime import datetime, timedelta\n","import pandas as pd\n","from transformers import AutoTokenizer\n","from transformers import TFAutoModelForSequenceClassification\n","import tensorflow as tf\n","from tensorflow.keras.losses import SparseCategoricalCrossentropy\n","\n","import numpy as np\n","import pandas as pd\n","\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import matthews_corrcoef\n","\n","\n","import pyarrow as pa\n","import pyarrow.dataset as ds\n","import pandas as pd\n","from datasets import Dataset\n","\n","import re\n","import csv\n","from transformers import pipeline\n","import torch.nn.functional as F\n","from transformers import AutoTokenizer , AutoModelForSequenceClassification\n","import torch\n","\n","import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","\n","import pandas\n","from tqdm import tqdm\n","\n","def labeller(directory,dataset):\n","    tokenizer = AutoTokenizer.from_pretrained(directory)\n","    model = AutoModelForSequenceClassification.from_pretrained(directory)\n","    classifier = pipeline(\"sentiment-analysis\", model = model, tokenizer = tokenizer,return_all_scores=True)\n","    #res = classifier(\"good\")\n","    #print(res)\n","    df = dataset.copy()\n","    #df = pd.DataFrame(columns = ['text', 'real_label', 'Negative','Neutral','Positive',])\n","    guess = []\n","    pos = []\n","    neg = []\n","    neu = []\n","\n","    for text in dataset['tweet']:  \n","          res = classifier(text)[0]\n","          r = {res[0]['label']:res[0]['score'], res[1]['label']:res[1]['score'], res[2]['label']:res[2]['score']}\n","          pos.append(r['Positive'])\n","          neg.append(r['Negative'])\n","          neu.append(r['Neutral'])\n","    is_pass = False\n","    if len(pos) == len(neg) and len(pos) == len(neu):\n","      print(\"pass equal pos neg neu length\")\n","      if len(pos) == dataset.shape[0]:\n","        print(\"pass dataset equality\")\n","        is_pass = True\n","      else:\n","        print(\"fail dataset equality\")\n","    else:\n","      print(\"fail equal pos neg neu length\")\n","    \n","    df[\"Positive\"] = pos\n","    df[\"Negative\"] = neg\n","    df['Neutral'] = neu\n","    return df,is_pass\n","\n","#df = labeller(directory,valid)\n","#display(df)\n","\n","#df.to_csv(\"/notebooks/fyp/final_modelV2/valid_F2_lex_head.csv\")\n","#num = 1\n","size = 3\n","start = 0 + (num-1)*size\n","end = (num)*size\n","num_ls = list(range(start,end))\n","print(num_ls)\n","for i in num_ls:\n","  path = \"/content/drive/MyDrive/fyp/fyp2/final models and datasets/lstm/dataset/bitcoin_unused_clean_tweepy/lstm_data_cleaned_\" + str(i) + \".csv\" \n","  dir = \"/content/drive/MyDrive/fyp/fyp2/final models and datasets/lstm/final model\"\n","  save_path = \"/content/drive/MyDrive/fyp/fyp2/final models and datasets/lstm/dataset/bitcoin_unused_clean_tweepy_labelled/\" + \"unused_bitcoin_labelled_\" + str(i) + \".csv\"\n","  df = pd.read_csv(path)\n","#display(df)\n","  df,ispass = labeller(dir,df)\n","  print(\"saving:\", save_path)\n","  print(\"did pass: \" , ispass)\n","  #display(df)\n","  df.to_csv(save_path)\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Kvx1-rNK3C9","executionInfo":{"status":"ok","timestamp":1662239106148,"user_tz":-60,"elapsed":25934,"user":{"displayName":"S Rahman","userId":"04000762971548563689"}},"outputId":"9b8e7c6e-232a-4621-be46-3376fa47c5c3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"rk4vM3nqH2bM"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1ywd-kj6CGBam4b2bP3hHp1PuVikZBWn8","timestamp":1662239160295},{"file_id":"1hXTWGU6ZM3ICMz2RDhTIYlkQf2XhItqU","timestamp":1662239116109},{"file_id":"1Ixlgeylib1tlH3KHxhEPoo_TaX-deVOL","timestamp":1662239046714},{"file_id":"172GyjUhLC5lxENq8Df0toQecpoj7xQl3","timestamp":1662238995707},{"file_id":"1tz2L_0IWzfv67rW5lPR-GZ_ptt4X3-ap","timestamp":1662238965874},{"file_id":"1qghJJrexiumvglFBfx5O9im2T0XAreEp","timestamp":1662238890506},{"file_id":"1szm_yivTTcpICHQgXJmelUPg-cXrLZKs","timestamp":1662237253075}],"mount_file_id":"1ywd-kj6CGBam4b2bP3hHp1PuVikZBWn8","authorship_tag":"ABX9TyPmH+FCver2WZZgq5zNl9uF"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}