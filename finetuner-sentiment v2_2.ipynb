{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":86353,"status":"ok","timestamp":1659728903744,"user":{"displayName":"S Rahman","userId":"04000762971548563689"},"user_tz":-60},"id":"klpNNdQNRAzv","outputId":"ac827b5d-2986-461b-b6c3-b8616eef4dc1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32384,"status":"ok","timestamp":1659728936071,"user":{"displayName":"S Rahman","userId":"04000762971548563689"},"user_tz":-60},"id":"iX00mr6WfSHG","outputId":"9f842185-66ee-498a-bc07-9fba81da5488"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.21.1-py3-none-any.whl (4.7 MB)\n","\u001b[K     |████████████████████████████████| 4.7 MB 12.3 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 56.6 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 60.2 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n","\u001b[K     |████████████████████████████████| 101 kB 10.8 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.21.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.4.0-py3-none-any.whl (365 kB)\n","\u001b[K     |████████████████████████████████| 365 kB 12.2 MB/s \n","\u001b[?25hCollecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n","Collecting xxhash\n","  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 49.6 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.12.0)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.13-py37-none-any.whl (115 kB)\n","\u001b[K     |████████████████████████████████| 115 kB 60.8 MB/s \n","\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Collecting fsspec[http]>=2021.11.1\n","  Downloading fsspec-2022.7.1-py3-none-any.whl (141 kB)\n","\u001b[K     |████████████████████████████████| 141 kB 63.6 MB/s \n","\u001b[?25hRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.8.1)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n","Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 59.6 MB/s \n","\u001b[?25hRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.1)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: urllib3, fsspec, xxhash, responses, multiprocess, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","Successfully installed datasets-2.4.0 fsspec-2022.7.1 multiprocess-0.70.13 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 12.0 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting GPUtil\n","  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n","Building wheels for collected packages: GPUtil\n","  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7411 sha256=db21e1f744fb520483ac439c2b7806d02cea4691143905fc07678a8217a6cb67\n","  Stored in directory: /root/.cache/pip/wheels/6e/f8/83/534c52482d6da64622ddbf72cd93c35d2ef2881b78fd08ff0c\n","Successfully built GPUtil\n","Installing collected packages: GPUtil\n","Successfully installed GPUtil-1.4.0\n"]}],"source":["!pip install transformers\n","!pip install datasets\n","!pip install sentencepiece\n","!pip install GPUtil\n","import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n","#!pip install wandb\n","import json\n","from transformers import AutoTokenizer\n","from transformers import TFAutoModelForSequenceClassification\n","import tensorflow as tf\n","from tensorflow.keras.losses import SparseCategoricalCrossentropy\n","\n","import numpy as np\n","import pandas as pd\n","\n","\n","\n","\n","import pyarrow as pa\n","import pyarrow.dataset as ds\n","import pandas as pd\n","from datasets import Dataset"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"NoSFcYvATZJ_","executionInfo":{"status":"ok","timestamp":1659728942247,"user_tz":-60,"elapsed":6251,"user":{"displayName":"S Rahman","userId":"04000762971548563689"}}},"outputs":[],"source":["\n","def ConvertLabel2ModelLabel(label):\n","  if label == 'Positive':\n","    o = 2\n","  elif label == 'Neutral':\n","    o = 1\n","  elif label == 'Negative':\n","    o = 0\n","  elif label == 'spam':\n","    o = 1\n","  else: \n","    print(\" error at ConvertLabel2ModelLabel label is \" , label)\n","    o = np.nan\n","  return o\n","\n","import torch\n","from GPUtil import showUtilization as gpu_usage\n","from numba import cuda\n","\n","def free_gpu_cache():\n","    print(\"Initial GPU Usage\")\n","    gpu_usage()                             \n","\n","    torch.cuda.empty_cache()\n","\n","    cuda.select_device(0)\n","    cuda.close()\n","    cuda.select_device(0)\n","\n","    print(\"GPU Usage after emptying the cache\")\n","    gpu_usage()"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":1450,"status":"ok","timestamp":1659728943663,"user":{"displayName":"S Rahman","userId":"04000762971548563689"},"user_tz":-60},"id":"0Yk0sHM_ff68","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"47e3174f-5f92-4e3e-ed11-2327ec4a4687"},"outputs":[{"output_type":"display_data","data":{"text/plain":["      Unnamed: 0                                               text     label  \\\n","0            339  КриптоВести BTC 🤘  Blockasset Taps Well-Known ...  Positive   \n","1            747  Full thanks to  as they have analysed this Bit...   Neutral   \n","2            301  __crypto _tw  🔥 SanjiInu 🔥  💥 KYC, CHARITY, NF...   Neutral   \n","3           1743  $btc btc health check! No custom death cross; ...   Neutral   \n","4           1108  44 🏦FTX | BTC PERP  🦋 If you have trouble imag...   Neutral   \n","...          ...                                                ...       ...   \n","2785         683  This will be very useful in the future because...  Positive   \n","2786        1451  And without Bitcoin Maxies hyping Bitcoin , th...  Positive   \n","2787        1106  11 IST   88.724  37996.605 ₿  3371120.946  253...  Positive   \n","2788        1787                     Bitcoin is Liberation Network.  Positive   \n","2789         344  bitcoin is the best MONEY in the history of ma...   Neutral   \n","\n","             source quality  \n","0      new_turk_low     low  \n","1     new_turk_high    high  \n","2       self_manual    high  \n","3      new_turk_low     low  \n","4      new_turk_low     low  \n","...             ...     ...  \n","2785   new_turk_low     low  \n","2786   new_turk_low     low  \n","2787   new_turk_low     low  \n","2788   new_turk_low     low  \n","2789   new_turk_low     low  \n","\n","[2790 rows x 5 columns]"],"text/html":["\n","  <div id=\"df-c52879ee-2cf9-4337-b2e5-e80af749c2c7\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>text</th>\n","      <th>label</th>\n","      <th>source</th>\n","      <th>quality</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>339</td>\n","      <td>КриптоВести BTC 🤘  Blockasset Taps Well-Known ...</td>\n","      <td>Positive</td>\n","      <td>new_turk_low</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>747</td>\n","      <td>Full thanks to  as they have analysed this Bit...</td>\n","      <td>Neutral</td>\n","      <td>new_turk_high</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>301</td>\n","      <td>__crypto _tw  🔥 SanjiInu 🔥  💥 KYC, CHARITY, NF...</td>\n","      <td>Neutral</td>\n","      <td>self_manual</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1743</td>\n","      <td>$btc btc health check! No custom death cross; ...</td>\n","      <td>Neutral</td>\n","      <td>new_turk_low</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1108</td>\n","      <td>44 🏦FTX | BTC PERP  🦋 If you have trouble imag...</td>\n","      <td>Neutral</td>\n","      <td>new_turk_low</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2785</th>\n","      <td>683</td>\n","      <td>This will be very useful in the future because...</td>\n","      <td>Positive</td>\n","      <td>new_turk_low</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>2786</th>\n","      <td>1451</td>\n","      <td>And without Bitcoin Maxies hyping Bitcoin , th...</td>\n","      <td>Positive</td>\n","      <td>new_turk_low</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>2787</th>\n","      <td>1106</td>\n","      <td>11 IST   88.724  37996.605 ₿  3371120.946  253...</td>\n","      <td>Positive</td>\n","      <td>new_turk_low</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>2788</th>\n","      <td>1787</td>\n","      <td>Bitcoin is Liberation Network.</td>\n","      <td>Positive</td>\n","      <td>new_turk_low</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>2789</th>\n","      <td>344</td>\n","      <td>bitcoin is the best MONEY in the history of ma...</td>\n","      <td>Neutral</td>\n","      <td>new_turk_low</td>\n","      <td>low</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2790 rows × 5 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c52879ee-2cf9-4337-b2e5-e80af749c2c7')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c52879ee-2cf9-4337-b2e5-e80af749c2c7 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c52879ee-2cf9-4337-b2e5-e80af749c2c7');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["      Unnamed: 0                                               text     label  \\\n","0             71  Full thanks to  as they have analysed this Bit...  Positive   \n","1            266             Typing mistake for Satoshi not bitcoin   Neutral   \n","2            410  Saitama SaitamaWolfPack SaitamaInu SaitaMask $...   Neutral   \n","3            333  100%, the nuclear industry has no idea what is...   Neutral   \n","4            401  airdrop Airdrops Crypto BSC DeFi Polygon Bitco...   Neutral   \n","...          ...                                                ...       ...   \n","1190         171  This is a very good project so don't miss to j...  Positive   \n","1191         319        Whoever didn’t panic sell we made it 🤝🎉 BTC  Positive   \n","1192         896  To know more about IPOs and Unlisted shares, c...   Neutral   \n","1193         425  Soon to the moon 🌜   Unitycol $Unity Unityprot...  Positive   \n","1194         153  Bitcoin Price     $48665.02     $37554.85     ...   Neutral   \n","\n","                source quality  \n","0     incomplete_valid    high  \n","1     incomplete_valid    high  \n","2     incomplete_valid    high  \n","3        new_turk_high    high  \n","4          self_manual    high  \n","...                ...     ...  \n","1190     new_turk_high    high  \n","1191     new_turk_high    high  \n","1192     new_turk_high    high  \n","1193  incomplete_valid    high  \n","1194     new_turk_high    high  \n","\n","[1195 rows x 5 columns]"],"text/html":["\n","  <div id=\"df-e2fafece-945d-40a8-a724-f26b213873e9\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>text</th>\n","      <th>label</th>\n","      <th>source</th>\n","      <th>quality</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>71</td>\n","      <td>Full thanks to  as they have analysed this Bit...</td>\n","      <td>Positive</td>\n","      <td>incomplete_valid</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>266</td>\n","      <td>Typing mistake for Satoshi not bitcoin</td>\n","      <td>Neutral</td>\n","      <td>incomplete_valid</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>410</td>\n","      <td>Saitama SaitamaWolfPack SaitamaInu SaitaMask $...</td>\n","      <td>Neutral</td>\n","      <td>incomplete_valid</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>333</td>\n","      <td>100%, the nuclear industry has no idea what is...</td>\n","      <td>Neutral</td>\n","      <td>new_turk_high</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>401</td>\n","      <td>airdrop Airdrops Crypto BSC DeFi Polygon Bitco...</td>\n","      <td>Neutral</td>\n","      <td>self_manual</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1190</th>\n","      <td>171</td>\n","      <td>This is a very good project so don't miss to j...</td>\n","      <td>Positive</td>\n","      <td>new_turk_high</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>1191</th>\n","      <td>319</td>\n","      <td>Whoever didn’t panic sell we made it 🤝🎉 BTC</td>\n","      <td>Positive</td>\n","      <td>new_turk_high</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>1192</th>\n","      <td>896</td>\n","      <td>To know more about IPOs and Unlisted shares, c...</td>\n","      <td>Neutral</td>\n","      <td>new_turk_high</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>1193</th>\n","      <td>425</td>\n","      <td>Soon to the moon 🌜   Unitycol $Unity Unityprot...</td>\n","      <td>Positive</td>\n","      <td>incomplete_valid</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>1194</th>\n","      <td>153</td>\n","      <td>Bitcoin Price     $48665.02     $37554.85     ...</td>\n","      <td>Neutral</td>\n","      <td>new_turk_high</td>\n","      <td>high</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1195 rows × 5 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2fafece-945d-40a8-a724-f26b213873e9')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e2fafece-945d-40a8-a724-f26b213873e9 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e2fafece-945d-40a8-a724-f26b213873e9');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["      Unnamed: 0                                               text     label  \\\n","1            747  Full thanks to  as they have analysed this Bit...   Neutral   \n","2            301  __crypto _tw  🔥 SanjiInu 🔥  💥 KYC, CHARITY, NF...   Neutral   \n","6            758  Full thanks to  as they have analysed this Bit...   Neutral   \n","15           285  BTC DOMINANCE  BULLISH PENNANT READY FOR BREAKOUT  Positive   \n","25           530  Mining Farm Turning Waste Coal Into Bitcoin Ra...  Positive   \n","...          ...                                                ...       ...   \n","2762          11  Bitcoin interoperability platform Interlay rai...  Positive   \n","2772         426  🇧🇷 BRL - R$ 0.00238059 🇺🇸 USD - $ 0.00042746 🇪...   Neutral   \n","2775         652         Current Bitcoin Price is $40714 BTC Crypto   Neutral   \n","2780         140  btc Crypto  cryptocurrency   Target 1 close.  ...  Positive   \n","2783         330  CBNEWS WEEKLY CRYPTO WRAPUP!!!  ZILLIQA AIR DR...   Neutral   \n","\n","             source quality  \n","1     new_turk_high    high  \n","2       self_manual    high  \n","6     new_turk_high    high  \n","15           manual    high  \n","25    new_turk_high    high  \n","...             ...     ...  \n","2762  new_turk_high    high  \n","2772    self_manual    high  \n","2775  new_turk_high    high  \n","2780  new_turk_high    high  \n","2783    self_manual    high  \n","\n","[539 rows x 5 columns]"],"text/html":["\n","  <div id=\"df-2d2cc752-146b-40a3-b784-86433d40b360\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>text</th>\n","      <th>label</th>\n","      <th>source</th>\n","      <th>quality</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>747</td>\n","      <td>Full thanks to  as they have analysed this Bit...</td>\n","      <td>Neutral</td>\n","      <td>new_turk_high</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>301</td>\n","      <td>__crypto _tw  🔥 SanjiInu 🔥  💥 KYC, CHARITY, NF...</td>\n","      <td>Neutral</td>\n","      <td>self_manual</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>758</td>\n","      <td>Full thanks to  as they have analysed this Bit...</td>\n","      <td>Neutral</td>\n","      <td>new_turk_high</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>285</td>\n","      <td>BTC DOMINANCE  BULLISH PENNANT READY FOR BREAKOUT</td>\n","      <td>Positive</td>\n","      <td>manual</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>530</td>\n","      <td>Mining Farm Turning Waste Coal Into Bitcoin Ra...</td>\n","      <td>Positive</td>\n","      <td>new_turk_high</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2762</th>\n","      <td>11</td>\n","      <td>Bitcoin interoperability platform Interlay rai...</td>\n","      <td>Positive</td>\n","      <td>new_turk_high</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>2772</th>\n","      <td>426</td>\n","      <td>🇧🇷 BRL - R$ 0.00238059 🇺🇸 USD - $ 0.00042746 🇪...</td>\n","      <td>Neutral</td>\n","      <td>self_manual</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>2775</th>\n","      <td>652</td>\n","      <td>Current Bitcoin Price is $40714 BTC Crypto</td>\n","      <td>Neutral</td>\n","      <td>new_turk_high</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>2780</th>\n","      <td>140</td>\n","      <td>btc Crypto  cryptocurrency   Target 1 close.  ...</td>\n","      <td>Positive</td>\n","      <td>new_turk_high</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>2783</th>\n","      <td>330</td>\n","      <td>CBNEWS WEEKLY CRYPTO WRAPUP!!!  ZILLIQA AIR DR...</td>\n","      <td>Neutral</td>\n","      <td>self_manual</td>\n","      <td>high</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>539 rows × 5 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d2cc752-146b-40a3-b784-86433d40b360')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2d2cc752-146b-40a3-b784-86433d40b360 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2d2cc752-146b-40a3-b784-86433d40b360');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["      Unnamed: 0                                               text     label  \\\n","0            339  КриптоВести BTC 🤘  Blockasset Taps Well-Known ...  Positive   \n","3           1743  $btc btc health check! No custom death cross; ...   Neutral   \n","4           1108  44 🏦FTX | BTC PERP  🦋 If you have trouble imag...   Neutral   \n","5            103             Bitcoin maxis are born in bear markets  Positive   \n","7           1768  BTC has risen by 9.19% in the last week. The p...   Neutral   \n","...          ...                                                ...       ...   \n","2785         683  This will be very useful in the future because...  Positive   \n","2786        1451  And without Bitcoin Maxies hyping Bitcoin , th...  Positive   \n","2787        1106  11 IST   88.724  37996.605 ₿  3371120.946  253...  Positive   \n","2788        1787                     Bitcoin is Liberation Network.  Positive   \n","2789         344  bitcoin is the best MONEY in the history of ma...   Neutral   \n","\n","            source quality  \n","0     new_turk_low     low  \n","3     new_turk_low     low  \n","4     new_turk_low     low  \n","5     new_turk_low     low  \n","7     new_turk_low     low  \n","...            ...     ...  \n","2785  new_turk_low     low  \n","2786  new_turk_low     low  \n","2787  new_turk_low     low  \n","2788  new_turk_low     low  \n","2789  new_turk_low     low  \n","\n","[2251 rows x 5 columns]"],"text/html":["\n","  <div id=\"df-7f422f78-8ff5-4ddc-b511-9bae864f4601\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>text</th>\n","      <th>label</th>\n","      <th>source</th>\n","      <th>quality</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>339</td>\n","      <td>КриптоВести BTC 🤘  Blockasset Taps Well-Known ...</td>\n","      <td>Positive</td>\n","      <td>new_turk_low</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1743</td>\n","      <td>$btc btc health check! No custom death cross; ...</td>\n","      <td>Neutral</td>\n","      <td>new_turk_low</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1108</td>\n","      <td>44 🏦FTX | BTC PERP  🦋 If you have trouble imag...</td>\n","      <td>Neutral</td>\n","      <td>new_turk_low</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>103</td>\n","      <td>Bitcoin maxis are born in bear markets</td>\n","      <td>Positive</td>\n","      <td>new_turk_low</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1768</td>\n","      <td>BTC has risen by 9.19% in the last week. The p...</td>\n","      <td>Neutral</td>\n","      <td>new_turk_low</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2785</th>\n","      <td>683</td>\n","      <td>This will be very useful in the future because...</td>\n","      <td>Positive</td>\n","      <td>new_turk_low</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>2786</th>\n","      <td>1451</td>\n","      <td>And without Bitcoin Maxies hyping Bitcoin , th...</td>\n","      <td>Positive</td>\n","      <td>new_turk_low</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>2787</th>\n","      <td>1106</td>\n","      <td>11 IST   88.724  37996.605 ₿  3371120.946  253...</td>\n","      <td>Positive</td>\n","      <td>new_turk_low</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>2788</th>\n","      <td>1787</td>\n","      <td>Bitcoin is Liberation Network.</td>\n","      <td>Positive</td>\n","      <td>new_turk_low</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>2789</th>\n","      <td>344</td>\n","      <td>bitcoin is the best MONEY in the history of ma...</td>\n","      <td>Neutral</td>\n","      <td>new_turk_low</td>\n","      <td>low</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2251 rows × 5 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f422f78-8ff5-4ddc-b511-9bae864f4601')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7f422f78-8ff5-4ddc-b511-9bae864f4601 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7f422f78-8ff5-4ddc-b511-9bae864f4601');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}],"source":["train_path = '/content/drive/MyDrive/fyp/fyp2/final models and datasets/dataset/dataset_new_with_self_label_3.0:4.0:4.0/train_dataset.csv'\n","valid_path = '/content/drive/MyDrive/fyp/fyp2/final models and datasets/dataset/dataset_new_with_self_label_3.0:4.0:4.0/valid_dataset.csv'\n","#model_name = \"Tomas23/twitter-roberta-base-mar2022-finetuned-sentiment\"\n","#out_dir = '/content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/tomas23_3:4:4/with_high'\n","#out_dir2 = '/content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/tomas23_3:4:4/with_high_then_low'\n","\n","import shutil\n","\n","\n","\n","\n","\n","name_of_text_column = \"text\"\n","hyperparameter_tuning = False\n","reduce_ = False\n","num_hyper_trails = 100\n","epoch = 60\n","\n","df_train = pd.read_csv(train_path)\n","\n","df_train_high = df_train[df_train['quality']==\"high\"]\n","df_train_low = df_train[df_train['quality']==\"low\"]\n","\n","df_valid = pd.read_csv(valid_path)\n","\n","display(df_train)\n","display(df_valid)\n","display(df_train_high)\n","display(df_train_low)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":95,"status":"ok","timestamp":1659728943664,"user":{"displayName":"S Rahman","userId":"04000762971548563689"},"user_tz":-60},"id":"GoIvErk1T_LX","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"96e99ad2-d0c6-48e2-cebc-bc71c77f7bda"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  after removing the cwd from sys.path.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \"\"\"\n"]},{"output_type":"display_data","data":{"text/plain":["      Unnamed: 0                                               text  label  \\\n","0            339  КриптоВести BTC 🤘  Blockasset Taps Well-Known ...      2   \n","1            747  Full thanks to  as they have analysed this Bit...      1   \n","2            301  __crypto _tw  🔥 SanjiInu 🔥  💥 KYC, CHARITY, NF...      1   \n","3           1743  $btc btc health check! No custom death cross; ...      1   \n","4           1108  44 🏦FTX | BTC PERP  🦋 If you have trouble imag...      1   \n","...          ...                                                ...    ...   \n","2785         683  This will be very useful in the future because...      2   \n","2786        1451  And without Bitcoin Maxies hyping Bitcoin , th...      2   \n","2787        1106  11 IST   88.724  37996.605 ₿  3371120.946  253...      2   \n","2788        1787                     Bitcoin is Liberation Network.      2   \n","2789         344  bitcoin is the best MONEY in the history of ma...      1   \n","\n","             source quality  \n","0      new_turk_low     low  \n","1     new_turk_high    high  \n","2       self_manual    high  \n","3      new_turk_low     low  \n","4      new_turk_low     low  \n","...             ...     ...  \n","2785   new_turk_low     low  \n","2786   new_turk_low     low  \n","2787   new_turk_low     low  \n","2788   new_turk_low     low  \n","2789   new_turk_low     low  \n","\n","[2790 rows x 5 columns]"],"text/html":["\n","  <div id=\"df-7e6b72c3-7b4a-4c38-b480-a28d0a89d5e5\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>text</th>\n","      <th>label</th>\n","      <th>source</th>\n","      <th>quality</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>339</td>\n","      <td>КриптоВести BTC 🤘  Blockasset Taps Well-Known ...</td>\n","      <td>2</td>\n","      <td>new_turk_low</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>747</td>\n","      <td>Full thanks to  as they have analysed this Bit...</td>\n","      <td>1</td>\n","      <td>new_turk_high</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>301</td>\n","      <td>__crypto _tw  🔥 SanjiInu 🔥  💥 KYC, CHARITY, NF...</td>\n","      <td>1</td>\n","      <td>self_manual</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1743</td>\n","      <td>$btc btc health check! No custom death cross; ...</td>\n","      <td>1</td>\n","      <td>new_turk_low</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1108</td>\n","      <td>44 🏦FTX | BTC PERP  🦋 If you have trouble imag...</td>\n","      <td>1</td>\n","      <td>new_turk_low</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2785</th>\n","      <td>683</td>\n","      <td>This will be very useful in the future because...</td>\n","      <td>2</td>\n","      <td>new_turk_low</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>2786</th>\n","      <td>1451</td>\n","      <td>And without Bitcoin Maxies hyping Bitcoin , th...</td>\n","      <td>2</td>\n","      <td>new_turk_low</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>2787</th>\n","      <td>1106</td>\n","      <td>11 IST   88.724  37996.605 ₿  3371120.946  253...</td>\n","      <td>2</td>\n","      <td>new_turk_low</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>2788</th>\n","      <td>1787</td>\n","      <td>Bitcoin is Liberation Network.</td>\n","      <td>2</td>\n","      <td>new_turk_low</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>2789</th>\n","      <td>344</td>\n","      <td>bitcoin is the best MONEY in the history of ma...</td>\n","      <td>1</td>\n","      <td>new_turk_low</td>\n","      <td>low</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2790 rows × 5 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7e6b72c3-7b4a-4c38-b480-a28d0a89d5e5')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7e6b72c3-7b4a-4c38-b480-a28d0a89d5e5 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7e6b72c3-7b4a-4c38-b480-a28d0a89d5e5');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["      Unnamed: 0                                               text  label  \\\n","0             71  Full thanks to  as they have analysed this Bit...      2   \n","1            266             Typing mistake for Satoshi not bitcoin      1   \n","2            410  Saitama SaitamaWolfPack SaitamaInu SaitaMask $...      1   \n","3            333  100%, the nuclear industry has no idea what is...      1   \n","4            401  airdrop Airdrops Crypto BSC DeFi Polygon Bitco...      1   \n","...          ...                                                ...    ...   \n","1190         171  This is a very good project so don't miss to j...      2   \n","1191         319        Whoever didn’t panic sell we made it 🤝🎉 BTC      2   \n","1192         896  To know more about IPOs and Unlisted shares, c...      1   \n","1193         425  Soon to the moon 🌜   Unitycol $Unity Unityprot...      2   \n","1194         153  Bitcoin Price     $48665.02     $37554.85     ...      1   \n","\n","                source quality  \n","0     incomplete_valid    high  \n","1     incomplete_valid    high  \n","2     incomplete_valid    high  \n","3        new_turk_high    high  \n","4          self_manual    high  \n","...                ...     ...  \n","1190     new_turk_high    high  \n","1191     new_turk_high    high  \n","1192     new_turk_high    high  \n","1193  incomplete_valid    high  \n","1194     new_turk_high    high  \n","\n","[1195 rows x 5 columns]"],"text/html":["\n","  <div id=\"df-94f44412-4559-4980-9322-d14acf6bee26\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>text</th>\n","      <th>label</th>\n","      <th>source</th>\n","      <th>quality</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>71</td>\n","      <td>Full thanks to  as they have analysed this Bit...</td>\n","      <td>2</td>\n","      <td>incomplete_valid</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>266</td>\n","      <td>Typing mistake for Satoshi not bitcoin</td>\n","      <td>1</td>\n","      <td>incomplete_valid</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>410</td>\n","      <td>Saitama SaitamaWolfPack SaitamaInu SaitaMask $...</td>\n","      <td>1</td>\n","      <td>incomplete_valid</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>333</td>\n","      <td>100%, the nuclear industry has no idea what is...</td>\n","      <td>1</td>\n","      <td>new_turk_high</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>401</td>\n","      <td>airdrop Airdrops Crypto BSC DeFi Polygon Bitco...</td>\n","      <td>1</td>\n","      <td>self_manual</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1190</th>\n","      <td>171</td>\n","      <td>This is a very good project so don't miss to j...</td>\n","      <td>2</td>\n","      <td>new_turk_high</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>1191</th>\n","      <td>319</td>\n","      <td>Whoever didn’t panic sell we made it 🤝🎉 BTC</td>\n","      <td>2</td>\n","      <td>new_turk_high</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>1192</th>\n","      <td>896</td>\n","      <td>To know more about IPOs and Unlisted shares, c...</td>\n","      <td>1</td>\n","      <td>new_turk_high</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>1193</th>\n","      <td>425</td>\n","      <td>Soon to the moon 🌜   Unitycol $Unity Unityprot...</td>\n","      <td>2</td>\n","      <td>incomplete_valid</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>1194</th>\n","      <td>153</td>\n","      <td>Bitcoin Price     $48665.02     $37554.85     ...</td>\n","      <td>1</td>\n","      <td>new_turk_high</td>\n","      <td>high</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1195 rows × 5 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94f44412-4559-4980-9322-d14acf6bee26')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-94f44412-4559-4980-9322-d14acf6bee26 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-94f44412-4559-4980-9322-d14acf6bee26');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["      Unnamed: 0                                               text  label  \\\n","1            747  Full thanks to  as they have analysed this Bit...      1   \n","2            301  __crypto _tw  🔥 SanjiInu 🔥  💥 KYC, CHARITY, NF...      1   \n","6            758  Full thanks to  as they have analysed this Bit...      1   \n","15           285  BTC DOMINANCE  BULLISH PENNANT READY FOR BREAKOUT      2   \n","25           530  Mining Farm Turning Waste Coal Into Bitcoin Ra...      2   \n","...          ...                                                ...    ...   \n","2762          11  Bitcoin interoperability platform Interlay rai...      2   \n","2772         426  🇧🇷 BRL - R$ 0.00238059 🇺🇸 USD - $ 0.00042746 🇪...      1   \n","2775         652         Current Bitcoin Price is $40714 BTC Crypto      1   \n","2780         140  btc Crypto  cryptocurrency   Target 1 close.  ...      2   \n","2783         330  CBNEWS WEEKLY CRYPTO WRAPUP!!!  ZILLIQA AIR DR...      1   \n","\n","             source quality  \n","1     new_turk_high    high  \n","2       self_manual    high  \n","6     new_turk_high    high  \n","15           manual    high  \n","25    new_turk_high    high  \n","...             ...     ...  \n","2762  new_turk_high    high  \n","2772    self_manual    high  \n","2775  new_turk_high    high  \n","2780  new_turk_high    high  \n","2783    self_manual    high  \n","\n","[539 rows x 5 columns]"],"text/html":["\n","  <div id=\"df-ba8d86a1-a49d-4cf4-8413-45c6d59d48ca\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>text</th>\n","      <th>label</th>\n","      <th>source</th>\n","      <th>quality</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>747</td>\n","      <td>Full thanks to  as they have analysed this Bit...</td>\n","      <td>1</td>\n","      <td>new_turk_high</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>301</td>\n","      <td>__crypto _tw  🔥 SanjiInu 🔥  💥 KYC, CHARITY, NF...</td>\n","      <td>1</td>\n","      <td>self_manual</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>758</td>\n","      <td>Full thanks to  as they have analysed this Bit...</td>\n","      <td>1</td>\n","      <td>new_turk_high</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>285</td>\n","      <td>BTC DOMINANCE  BULLISH PENNANT READY FOR BREAKOUT</td>\n","      <td>2</td>\n","      <td>manual</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>530</td>\n","      <td>Mining Farm Turning Waste Coal Into Bitcoin Ra...</td>\n","      <td>2</td>\n","      <td>new_turk_high</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2762</th>\n","      <td>11</td>\n","      <td>Bitcoin interoperability platform Interlay rai...</td>\n","      <td>2</td>\n","      <td>new_turk_high</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>2772</th>\n","      <td>426</td>\n","      <td>🇧🇷 BRL - R$ 0.00238059 🇺🇸 USD - $ 0.00042746 🇪...</td>\n","      <td>1</td>\n","      <td>self_manual</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>2775</th>\n","      <td>652</td>\n","      <td>Current Bitcoin Price is $40714 BTC Crypto</td>\n","      <td>1</td>\n","      <td>new_turk_high</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>2780</th>\n","      <td>140</td>\n","      <td>btc Crypto  cryptocurrency   Target 1 close.  ...</td>\n","      <td>2</td>\n","      <td>new_turk_high</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>2783</th>\n","      <td>330</td>\n","      <td>CBNEWS WEEKLY CRYPTO WRAPUP!!!  ZILLIQA AIR DR...</td>\n","      <td>1</td>\n","      <td>self_manual</td>\n","      <td>high</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>539 rows × 5 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba8d86a1-a49d-4cf4-8413-45c6d59d48ca')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ba8d86a1-a49d-4cf4-8413-45c6d59d48ca button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ba8d86a1-a49d-4cf4-8413-45c6d59d48ca');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["      Unnamed: 0                                               text  label  \\\n","0            339  КриптоВести BTC 🤘  Blockasset Taps Well-Known ...      2   \n","3           1743  $btc btc health check! No custom death cross; ...      1   \n","4           1108  44 🏦FTX | BTC PERP  🦋 If you have trouble imag...      1   \n","5            103             Bitcoin maxis are born in bear markets      2   \n","7           1768  BTC has risen by 9.19% in the last week. The p...      1   \n","...          ...                                                ...    ...   \n","2785         683  This will be very useful in the future because...      2   \n","2786        1451  And without Bitcoin Maxies hyping Bitcoin , th...      2   \n","2787        1106  11 IST   88.724  37996.605 ₿  3371120.946  253...      2   \n","2788        1787                     Bitcoin is Liberation Network.      2   \n","2789         344  bitcoin is the best MONEY in the history of ma...      1   \n","\n","            source quality  \n","0     new_turk_low     low  \n","3     new_turk_low     low  \n","4     new_turk_low     low  \n","5     new_turk_low     low  \n","7     new_turk_low     low  \n","...            ...     ...  \n","2785  new_turk_low     low  \n","2786  new_turk_low     low  \n","2787  new_turk_low     low  \n","2788  new_turk_low     low  \n","2789  new_turk_low     low  \n","\n","[2251 rows x 5 columns]"],"text/html":["\n","  <div id=\"df-82a1102b-6378-4707-902e-6345d2baf738\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>text</th>\n","      <th>label</th>\n","      <th>source</th>\n","      <th>quality</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>339</td>\n","      <td>КриптоВести BTC 🤘  Blockasset Taps Well-Known ...</td>\n","      <td>2</td>\n","      <td>new_turk_low</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1743</td>\n","      <td>$btc btc health check! No custom death cross; ...</td>\n","      <td>1</td>\n","      <td>new_turk_low</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1108</td>\n","      <td>44 🏦FTX | BTC PERP  🦋 If you have trouble imag...</td>\n","      <td>1</td>\n","      <td>new_turk_low</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>103</td>\n","      <td>Bitcoin maxis are born in bear markets</td>\n","      <td>2</td>\n","      <td>new_turk_low</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1768</td>\n","      <td>BTC has risen by 9.19% in the last week. The p...</td>\n","      <td>1</td>\n","      <td>new_turk_low</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2785</th>\n","      <td>683</td>\n","      <td>This will be very useful in the future because...</td>\n","      <td>2</td>\n","      <td>new_turk_low</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>2786</th>\n","      <td>1451</td>\n","      <td>And without Bitcoin Maxies hyping Bitcoin , th...</td>\n","      <td>2</td>\n","      <td>new_turk_low</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>2787</th>\n","      <td>1106</td>\n","      <td>11 IST   88.724  37996.605 ₿  3371120.946  253...</td>\n","      <td>2</td>\n","      <td>new_turk_low</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>2788</th>\n","      <td>1787</td>\n","      <td>Bitcoin is Liberation Network.</td>\n","      <td>2</td>\n","      <td>new_turk_low</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>2789</th>\n","      <td>344</td>\n","      <td>bitcoin is the best MONEY in the history of ma...</td>\n","      <td>1</td>\n","      <td>new_turk_low</td>\n","      <td>low</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2251 rows × 5 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82a1102b-6378-4707-902e-6345d2baf738')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-82a1102b-6378-4707-902e-6345d2baf738 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-82a1102b-6378-4707-902e-6345d2baf738');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}],"source":["df_train['label'] = df_train['label'].apply(ConvertLabel2ModelLabel)\n","df_valid['label'] = df_valid['label'].apply(ConvertLabel2ModelLabel)\n","\n","df_train_high['label'] = df_train_high['label'].apply(ConvertLabel2ModelLabel)\n","df_train_low['label'] = df_train_low['label'].apply(ConvertLabel2ModelLabel)\n","\n","display(df_train)\n","display(df_valid)\n","display(df_train_high)\n","display(df_train_low)\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"SG6S7inA_RKv","executionInfo":{"status":"ok","timestamp":1659728943666,"user_tz":-60,"elapsed":28,"user":{"displayName":"S Rahman","userId":"04000762971548563689"}}},"outputs":[],"source":["from transformers import Trainer\n","from transformers import TrainingArguments\n","#learning_rate = 5e-05\n","#batch_size = 16\n","#eval_batch_size = 4\n","seed = 40\n","#optimizer = Adam \n","#with betas=(0.9,0.999) and epsilon=1e-08\n","adam_beta1 = 0.9\n","adam_beta2 =0.999\n","lr_scheduler_type = \"linear\"\n","num_epochs = 15\n","#args = TrainingArguments(\"test_trainer\",report_to=\"wandb\" ,logging_strategy = \"epoch\",evaluation_strategy=\"epoch\",learning_rate = learning_rate,num_train_epochs = num_epochs,lr_scheduler_type =lr_scheduler_type, adam_beta1 = adam_beta1,adam_beta2 =adam_beta2  )\n","\n","\n","def run_trainer(model_name,out_dir,epoch,batch_size,df_train,df_valid,):\n","  df_train = df_train[['text','label']].set_index('text')\n","  df_valid = df_valid[['text','label']].set_index('text')\n","  #display(df_train)\n","  #display(df_valid)\n","\n","  dataset = ds.dataset(pa.Table.from_pandas(df_valid).to_batches())\n","  ### convert to Huggingface dataset\n","  validation_dataset_torch = Dataset(pa.Table.from_pandas(df_valid))\n","\n","  dataset = ds.dataset(pa.Table.from_pandas(df_train).to_batches())\n","  ### convert to Huggingface dataset\n","  training_dataset_torch = Dataset(pa.Table.from_pandas(df_train))\n","\n","  #print(training_dataset_torch)\n","  #print(validation_dataset_torch)\n","\n","  from transformers import AutoTokenizer\n","\n","  tokenizer = AutoTokenizer.from_pretrained(model_name,model_max_length=512)\n","\n","\n","\n","  def tokenize_function(data):\n","      return tokenizer(data['text'], padding=\"max_length\", truncation=True,)\n","\n","\n","  train_dataset = training_dataset_torch.map(tokenize_function, batched=True)\n","  eval_dataset = validation_dataset_torch.map(tokenize_function, batched=True)\n","  print(train_dataset)\n","  print(eval_dataset)\n","\n","  import numpy as np\n","  from datasets import load_metric\n","\n","  metric = load_metric(\"matthews_correlation\")\n","\n","  def compute_metrics(eval_pred):\n","      logits, labels = eval_pred\n","      predictions = np.argmax(logits, axis=-1)\n","      return metric.compute(predictions=predictions, references=labels)\n","\n","\n","  from transformers import AutoModelForSequenceClassification\n","\n","  model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n","  #model.to(device)\n","  args = TrainingArguments(\n","      #'/content/drive/MyDrive/fyp/fyp2/model/model2-supervised/' + f\"{model_name}-finetuned-\",\n","      #'/content/' + f\"{model_name}-finetuned-\",\n","      out_dir,\n","      #report_to=\"wandb\",\n","      overwrite_output_dir = True,\n","      logging_dir = out_dir,\n","      evaluation_strategy = \"epoch\",\n","      logging_strategy = \"epoch\",\n","      #save_strategy = \"NO\",\n","      learning_rate=2.6510704963161386e-06,\n","      per_device_train_batch_size=batch_size,\n","      per_device_eval_batch_size=batch_size,\n","      num_train_epochs=epoch,\n","      weight_decay=0.01,\n","      metric_for_best_model='matthews_correlation',\n","      save_total_limit = 2,\n","      save_strategy = \"epoch\",\n","      load_best_model_at_end = True,\n","      seed = 18\n","      #push_to_hub=True,\n","  )\n","\n","\n","\n","  trainer = Trainer(\n","      model,\n","      args,\n","      train_dataset=train_dataset,\n","      eval_dataset=eval_dataset,\n","      tokenizer=tokenizer,\n","      compute_metrics=compute_metrics\n","  )\n","\n","  #trainer = Trainer(\n","    # model=model,\n","      #args=args,\n","    # train_dataset=train_dataset,\n","    #  eval_dataset=eval_dataset,\n","  #   compute_metrics=compute_metrics,\n","  #)\n","\n","\n","    # training\n","  train_result = trainer.train() \n","  logs = trainer.state.log_history\n","  # compute train results\n","  metrics = train_result.metrics\n","  max_train_samples = len(train_dataset)\n","  metrics[\"train_samples\"] = min(max_train_samples, len(train_dataset))\n","\n","  # save train results\n","  trainer.log_metrics(\"train\", metrics)\n","  trainer.save_metrics(\"train\", metrics)\n","\n","  # compute evaluation results\n","  metrics = trainer.evaluate()\n","  max_val_samples = len(eval_dataset)\n","  metrics[\"eval_samples\"] = min(max_val_samples, len(eval_dataset))\n","\n","  # save evaluation results\n","  trainer.log_metrics(\"eval\", metrics)\n","  trainer.save_metrics(\"eval\", metrics)\n","  import pickle\n","  save_logs_dir = out_dir\n","  name_logs = \"logs\"\n","  \n","  my_file = save_logs_dir + \"/\" + name_logs + \".p\"\n","  print(\"saving to \",my_file )\n","\n","  pickle.dump( logs, open( my_file, \"wb\" )    ) \n","\n","  ld = pickle.load( open( my_file, \"rb\" ) )\n","\n","\n","  print(logs)\n","  print(logs[2])\n","  print(type(logs))\n","\n","  print(ld)\n","  print(type(ld))\n","  print(logs == ld)\n","  \n","  import torch\n","  torch.cuda.is_available() \n","  from numba import cuda\n","  del trainer,args\n","  torch.cuda.empty_cache()\n","  #trainer.evaluate()\n","\n"]},{"cell_type":"code","source":["def run_both_training(model_name,out_dir=\"/content/drive/MyDrive/fyp/fyp2/final models and datasets/final models\",batch_size = 16,df_valid = df_valid):\n","  print(\"starting \" ,model_name)\n","  out = out_dir + \"/\" + model_name + \"/high\"\n"," \n","  if not os.path.exists(out):\n","    \n","    # Create a new directory because it does not exist \n","    os.makedirs(out)\n","  else:\n","    shutil.rmtree(out)\n","\n","  run_trainer(model_name=model_name,out_dir = out,epoch =40,df_train = df_train_high,df_valid=df_valid,batch_size=batch_size)\n","  torch.cuda.empty_cache()\n","  print(model_name,\" is completed\")\n","  #out = out_dir + \"/\" + model_name + \"/high_then_low\"\n","  #run_trainer(model_name=model_name,out_dir= out,epoch=50,df_train = df_train_low,df_valid=df_valid)"],"metadata":{"id":"bMAFQ9PVu5tY","executionInfo":{"status":"ok","timestamp":1659728943667,"user_tz":-60,"elapsed":27,"user":{"displayName":"S Rahman","userId":"04000762971548563689"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["#run_both_training(\"Tomas23/twitter-roberta-base-mar2022-finetuned-sentiment\")\n","\n","#run_both_training(\"cardiffnlp/bertweet-base-sentiment\")\n","#run_both_training(\"svalabs/twitter-xlm-roberta-bitcoin-sentiment\")\n","\n","run_both_training(\"cardiffnlp/twitter-xlm-roberta-base-sentiment\")\n","run_both_training(\"amansolanki/autonlp-Tweet-Sentiment-Extraction-20114061\")\n","\n","#run_both_training(\"finiteautomata/bertweet-base-sentiment-analysis\")\n","\n","\n"],"metadata":{"id":"FK_NHP6ZyFIH","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["a47b890abfa7408aa1e04c91724993e2","b57cc314463e489cb4af3281b43225ec","03c03970751549a088df90c325fade8c","2ca9c13c82e1428694c86b06c1435bf9","7beb17e10f4348b88cd78604524133cc","50ddf7a0d04d466fb2bb4d5ce76206f9","6ce1424994cc4c8daa70c5fbec411fb5","7f5c4ee2ea2044cea05827252a7f48fd","449cf2438f5f47a8bb3005900c7ad6e9","9606a06183bc494390b71b1dff294fe8","d79756a72a024c7d897e18c37b5cfa4f","4ff913a19ba04e7cab1292d1c3db9f7a","776cbd01a0ca481ba6126288605144d3","5070b0fa7e3f4d51830270d206b2285e","3d7b993355b144559d16f418b23820d1","cad28b1d4b0d4dfeb0b7ca4aa02253b7","7de83b91f1394a078b27a898cc2db31a","cabaf54cd29045aeadee55bc9278602f","2ae8f5a68b654b41b3520c4ca15f6d63","b9283f5371a34b97816fe410662cb2d7","789e4d1471834305b02dc88fac9aef6b","28e8b1cdbe9a4edea30cda21ee9d7fcd","b854e0b0a79f429cadfe913385376071","bcdbea9c95bd4c6aad656ca6683bde15","8436c2b52b9545888ee04221f44d5729","2905a7910d8644a1abbc4bac9283ce4c","950115fa5de94bee965d305b92d1737d","2d36237fa31144cfadabbb75685bd33e","5daf3d5081294d908766e4c42294c488","b6e9284b66494ed2b4033641ed142541","87ddc03601414ef3bcfdc981d003efe0","dd8ce73eb6a14422b335342738a6842f","f1bd7fb1086b46d3acad8bee6e388d12","df65016fb89f4ad085092fbf27dd150c","31b0dc3f66aa4b3797c2067af53d84b6","23dd246841514124b8818bf52efb44f4","e68b02f5a4184636b4051e7348cfb379","4a0999a0f0834426914b05d59e7c0d4c","c712a98f4c9e440699dd1984572f94d0","fb5291e362de4989b2ee8f5cea70149e","9246d2706f8d4786b4439d4de252f6b6","1b6320f3b022464a8d099f7b9ef8c490","cbf8a089118f47edbdaaefc06bcf4284","b6f1ee057ccc4ceabea22bacb1e5ed08","825fbe76622f433db599f764b87b341f","780599d793f647cfa8da2ddb9764dddd","a7a83107e4b849cc9b4e248ae60d7001","21c04731744042e48cda1195e18f8243","02f12be3a6854c7ba5c83f4680be8d3c","8de43060d045417399f8e3efc22f9484","62072a0b2b9c418fa096887d77aee5b3","5fd36132f0564948bc8b05b9e4337b64","77dcd3f89cb946298afe7d977260c66a","772ebbf364c44519a34fd5ae446bda66","b8a822e4cdb4458288ef5c611d2935c5","54d6ba6cb764405987a61d5cd1eeba48","eb9688c3daf04d7482589f66e2cd4ad7","eed6d26b8aff40e8a4ced18a63b93c5f","cfa2fb8690804e14b57e7f75d0c6575d","a3aba0ebbaa148c8a3c3f24e4a8b9826","7d22610fec5c466bb7653357e97e2340","51f3885f1d4d4bb9b77eb42264c1d282","0c8504f72bdd4687a5dd567cc935d2b9","8508853fa9cb464ebc600432f5318457","e21ffb3bd73845a78c13f24c48700d82","e1fa9e20de8741d492012c1f8c97d4db","ef29ed3d2b5f4153906d42c3bce1ea5a","b4823935b6334fcdb92f7688e4750cfd","fe161e8956e94af28f1236a73062ae2a","6fe1224f862e4ba48494b2577bbf47a4","223c27a2a539445a86459f81aa93fe6b","3e1f9720d9ee42be8f09286fa6f8a001","3a663d76cd32419cbe20ffc3478ec2ba","05d242e4ce2e4d1d9810dcf41e7128ca","86a509073e5d4422be8de8524bd34529","f7d3591cca7e4b66ace0fa8e83a34362","2dc1d7574ac14cf9b13fb7e40752f4c2"]},"outputId":"45d4d2e7-6273-4947-8d9f-0d334a7f97a9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["starting  cardiffnlp/twitter-xlm-roberta-base-sentiment\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading config.json:   0%|          | 0.00/841 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a47b890abfa7408aa1e04c91724993e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading sentencepiece.bpe.model:   0%|          | 0.00/4.83M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ff913a19ba04e7cab1292d1c3db9f7a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b854e0b0a79f429cadfe913385376071"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df65016fb89f4ad085092fbf27dd150c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"825fbe76622f433db599f764b87b341f"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset({\n","    features: ['label', 'text', 'input_ids', 'attention_mask'],\n","    num_rows: 539\n","})\n","Dataset({\n","    features: ['label', 'text', 'input_ids', 'attention_mask'],\n","    num_rows: 1195\n","})\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/1.71k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54d6ba6cb764405987a61d5cd1eeba48"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/1.04G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef29ed3d2b5f4153906d42c3bce1ea5a"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the training set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 539\n","  Num Epochs = 40\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 1360\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1269' max='1360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1269/1360 43:21 < 03:06, 0.49 it/s, Epoch 37.29/40]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Matthews Correlation</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.849600</td>\n","      <td>0.855335</td>\n","      <td>0.331002</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.748300</td>\n","      <td>0.831314</td>\n","      <td>0.250656</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.660600</td>\n","      <td>0.887890</td>\n","      <td>0.259650</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.578800</td>\n","      <td>0.943721</td>\n","      <td>0.251265</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.531500</td>\n","      <td>1.009977</td>\n","      <td>0.252969</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.489900</td>\n","      <td>1.113168</td>\n","      <td>0.262094</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.441700</td>\n","      <td>1.148519</td>\n","      <td>0.256793</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.412500</td>\n","      <td>1.205426</td>\n","      <td>0.253462</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.390000</td>\n","      <td>1.263606</td>\n","      <td>0.254410</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.353500</td>\n","      <td>1.322345</td>\n","      <td>0.255916</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.328800</td>\n","      <td>1.378124</td>\n","      <td>0.250248</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.287000</td>\n","      <td>1.393081</td>\n","      <td>0.253321</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.268600</td>\n","      <td>1.442235</td>\n","      <td>0.256512</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.247300</td>\n","      <td>1.521803</td>\n","      <td>0.255565</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.238800</td>\n","      <td>1.563557</td>\n","      <td>0.257199</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.224700</td>\n","      <td>1.566219</td>\n","      <td>0.259696</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>0.218000</td>\n","      <td>1.614941</td>\n","      <td>0.253914</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>0.205100</td>\n","      <td>1.617930</td>\n","      <td>0.256728</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>0.195200</td>\n","      <td>1.646765</td>\n","      <td>0.252498</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.163200</td>\n","      <td>1.702656</td>\n","      <td>0.252978</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>0.143500</td>\n","      <td>1.688201</td>\n","      <td>0.254928</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>0.157300</td>\n","      <td>1.717071</td>\n","      <td>0.258125</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>0.137400</td>\n","      <td>1.796023</td>\n","      <td>0.254512</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>0.123500</td>\n","      <td>1.809192</td>\n","      <td>0.256037</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>0.129500</td>\n","      <td>1.851433</td>\n","      <td>0.254097</td>\n","    </tr>\n","    <tr>\n","      <td>26</td>\n","      <td>0.126400</td>\n","      <td>1.919293</td>\n","      <td>0.251867</td>\n","    </tr>\n","    <tr>\n","      <td>27</td>\n","      <td>0.132500</td>\n","      <td>1.956270</td>\n","      <td>0.252166</td>\n","    </tr>\n","    <tr>\n","      <td>28</td>\n","      <td>0.102000</td>\n","      <td>2.001114</td>\n","      <td>0.246341</td>\n","    </tr>\n","    <tr>\n","      <td>29</td>\n","      <td>0.131100</td>\n","      <td>2.017981</td>\n","      <td>0.250311</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.109100</td>\n","      <td>2.016632</td>\n","      <td>0.252268</td>\n","    </tr>\n","    <tr>\n","      <td>31</td>\n","      <td>0.106500</td>\n","      <td>2.061511</td>\n","      <td>0.252586</td>\n","    </tr>\n","    <tr>\n","      <td>32</td>\n","      <td>0.108100</td>\n","      <td>2.072899</td>\n","      <td>0.256153</td>\n","    </tr>\n","    <tr>\n","      <td>33</td>\n","      <td>0.098100</td>\n","      <td>2.085574</td>\n","      <td>0.258008</td>\n","    </tr>\n","    <tr>\n","      <td>34</td>\n","      <td>0.091700</td>\n","      <td>2.087051</td>\n","      <td>0.253288</td>\n","    </tr>\n","    <tr>\n","      <td>35</td>\n","      <td>0.102000</td>\n","      <td>2.108172</td>\n","      <td>0.251429</td>\n","    </tr>\n","    <tr>\n","      <td>36</td>\n","      <td>0.102100</td>\n","      <td>2.129703</td>\n","      <td>0.250074</td>\n","    </tr>\n","    <tr>\n","      <td>37</td>\n","      <td>0.102200</td>\n","      <td>2.137974</td>\n","      <td>0.247193</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-34\n","Configuration saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-34/config.json\n","Model weights saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-34/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-34/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-34/special_tokens_map.json\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-68\n","Configuration saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-68/config.json\n","Model weights saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-68/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-68/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-68/special_tokens_map.json\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-102\n","Configuration saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-102/config.json\n","Model weights saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-102/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-102/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-102/special_tokens_map.json\n","Deleting older checkpoint [/content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-68] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-136\n","Configuration saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-136/config.json\n","Model weights saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-136/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-136/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-136/special_tokens_map.json\n","Deleting older checkpoint [/content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-102] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-170\n","Configuration saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-170/config.json\n","Model weights saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-170/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-170/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-170/special_tokens_map.json\n","Deleting older checkpoint [/content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-136] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-204\n","Configuration saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-204/config.json\n","Model weights saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-204/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-204/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-204/special_tokens_map.json\n","Deleting older checkpoint [/content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-170] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-238\n","Configuration saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-238/config.json\n","Model weights saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-238/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-238/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-238/special_tokens_map.json\n","Deleting older checkpoint [/content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-204] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-272\n","Configuration saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-272/config.json\n","Model weights saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-272/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-272/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-272/special_tokens_map.json\n","Deleting older checkpoint [/content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-238] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-306\n","Configuration saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-306/config.json\n","Model weights saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-306/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-306/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-306/special_tokens_map.json\n","Deleting older checkpoint [/content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-272] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-340\n","Configuration saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-340/config.json\n","Model weights saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-340/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-340/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-340/special_tokens_map.json\n","Deleting older checkpoint [/content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-306] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-374\n","Configuration saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-374/config.json\n","Model weights saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-374/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-374/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-374/special_tokens_map.json\n","Deleting older checkpoint [/content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-340] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-408\n","Configuration saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-408/config.json\n","Model weights saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-408/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-408/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-408/special_tokens_map.json\n","Deleting older checkpoint [/content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-374] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-442\n","Configuration saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-442/config.json\n","Model weights saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-442/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-442/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-442/special_tokens_map.json\n","Deleting older checkpoint [/content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-408] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-476\n","Configuration saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-476/config.json\n","Model weights saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-476/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-476/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-476/special_tokens_map.json\n","Deleting older checkpoint [/content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-442] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-510\n","Configuration saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-510/config.json\n","Model weights saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-510/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-510/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-510/special_tokens_map.json\n","Deleting older checkpoint [/content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-476] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-544\n","Configuration saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-544/config.json\n","Model weights saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-544/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-544/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-544/special_tokens_map.json\n","Deleting older checkpoint [/content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-510] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-578\n","Configuration saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-578/config.json\n","Model weights saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-578/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-578/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-578/special_tokens_map.json\n","Deleting older checkpoint [/content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-544] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-612\n","Configuration saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-612/config.json\n","Model weights saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-612/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-612/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-612/special_tokens_map.json\n","Deleting older checkpoint [/content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-578] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-646\n","Configuration saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-646/config.json\n","Model weights saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-646/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-646/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-646/special_tokens_map.json\n","Deleting older checkpoint [/content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-612] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-680\n","Configuration saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-680/config.json\n","Model weights saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-680/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-680/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-680/special_tokens_map.json\n","Deleting older checkpoint [/content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-646] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-714\n","Configuration saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-714/config.json\n","Model weights saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-714/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-714/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-714/special_tokens_map.json\n","Deleting older checkpoint [/content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-680] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-748\n","Configuration saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-748/config.json\n","Model weights saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-748/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-748/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-748/special_tokens_map.json\n","Deleting older checkpoint [/content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-714] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-782\n","Configuration saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-782/config.json\n","Model weights saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-782/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-782/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-782/special_tokens_map.json\n","Deleting older checkpoint [/content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-748] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-816\n","Configuration saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-816/config.json\n","Model weights saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-816/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-816/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-816/special_tokens_map.json\n","Deleting older checkpoint [/content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-782] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-850\n","Configuration saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-850/config.json\n","Model weights saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-850/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-850/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-850/special_tokens_map.json\n","Deleting older checkpoint [/content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-816] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-884\n","Configuration saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-884/config.json\n","Model weights saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-884/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-884/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-884/special_tokens_map.json\n","Deleting older checkpoint [/content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-850] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-918\n","Configuration saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-918/config.json\n","Model weights saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-918/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-918/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-918/special_tokens_map.json\n","Deleting older checkpoint [/content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-884] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-952\n","Configuration saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-952/config.json\n","Model weights saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-952/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-952/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-952/special_tokens_map.json\n","Deleting older checkpoint [/content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-918] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-986\n","Configuration saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-986/config.json\n","Model weights saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-986/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-986/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-986/special_tokens_map.json\n","Deleting older checkpoint [/content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-952] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-1020\n","Configuration saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-1020/config.json\n","Model weights saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-1020/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-1020/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-1020/special_tokens_map.json\n","Deleting older checkpoint [/content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-986] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-1054\n","Configuration saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-1054/config.json\n","Model weights saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-1054/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-1054/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-1054/special_tokens_map.json\n","Deleting older checkpoint [/content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-1020] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-1088\n","Configuration saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-1088/config.json\n","Model weights saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-1088/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-1088/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-1088/special_tokens_map.json\n","Deleting older checkpoint [/content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-1054] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-1122\n","Configuration saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-1122/config.json\n","Model weights saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-1122/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-1122/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-1122/special_tokens_map.json\n","Deleting older checkpoint [/content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-1088] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-1156\n","Configuration saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-1156/config.json\n","Model weights saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-1156/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-1156/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-1156/special_tokens_map.json\n","Deleting older checkpoint [/content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-1122] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-1190\n","Configuration saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-1190/config.json\n","Model weights saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-1190/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-1190/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-1190/special_tokens_map.json\n","Deleting older checkpoint [/content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-1156] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-1224\n","Configuration saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-1224/config.json\n","Model weights saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-1224/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-1224/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-1224/special_tokens_map.json\n","Deleting older checkpoint [/content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-1190] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-1258\n","Configuration saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-1258/config.json\n","Model weights saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-1258/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-1258/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-1258/special_tokens_map.json\n","Deleting older checkpoint [/content/drive/MyDrive/fyp/fyp2/final models and datasets/final models/cardiffnlp/twitter-xlm-roberta-base-sentiment/high/checkpoint-1224] due to args.save_total_limit\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IEUvCosOxZJF"},"outputs":[],"source":["!nvidia-smi "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-84QX-hcdTAm"},"outputs":[],"source":["!kill -9 -1"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"finetuner-sentiment v2_2.ipynb","provenance":[{"file_id":"1NrcZb-f3iK-NOB6kdsr4eWbqQP6hh08Y","timestamp":1659707013573},{"file_id":"1BUoiPdIj_YosKbOIoOiNQnE0VXVErHUg","timestamp":1659144449674}],"mount_file_id":"1NrcZb-f3iK-NOB6kdsr4eWbqQP6hh08Y","authorship_tag":"ABX9TyPrE6gPaSh42F9LRfDmAMQd"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"a47b890abfa7408aa1e04c91724993e2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b57cc314463e489cb4af3281b43225ec","IPY_MODEL_03c03970751549a088df90c325fade8c","IPY_MODEL_2ca9c13c82e1428694c86b06c1435bf9"],"layout":"IPY_MODEL_7beb17e10f4348b88cd78604524133cc"}},"b57cc314463e489cb4af3281b43225ec":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_50ddf7a0d04d466fb2bb4d5ce76206f9","placeholder":"​","style":"IPY_MODEL_6ce1424994cc4c8daa70c5fbec411fb5","value":"Downloading config.json: 100%"}},"03c03970751549a088df90c325fade8c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f5c4ee2ea2044cea05827252a7f48fd","max":841,"min":0,"orientation":"horizontal","style":"IPY_MODEL_449cf2438f5f47a8bb3005900c7ad6e9","value":841}},"2ca9c13c82e1428694c86b06c1435bf9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9606a06183bc494390b71b1dff294fe8","placeholder":"​","style":"IPY_MODEL_d79756a72a024c7d897e18c37b5cfa4f","value":" 841/841 [00:00&lt;00:00, 25.4kB/s]"}},"7beb17e10f4348b88cd78604524133cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50ddf7a0d04d466fb2bb4d5ce76206f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ce1424994cc4c8daa70c5fbec411fb5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7f5c4ee2ea2044cea05827252a7f48fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"449cf2438f5f47a8bb3005900c7ad6e9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9606a06183bc494390b71b1dff294fe8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d79756a72a024c7d897e18c37b5cfa4f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4ff913a19ba04e7cab1292d1c3db9f7a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_776cbd01a0ca481ba6126288605144d3","IPY_MODEL_5070b0fa7e3f4d51830270d206b2285e","IPY_MODEL_3d7b993355b144559d16f418b23820d1"],"layout":"IPY_MODEL_cad28b1d4b0d4dfeb0b7ca4aa02253b7"}},"776cbd01a0ca481ba6126288605144d3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7de83b91f1394a078b27a898cc2db31a","placeholder":"​","style":"IPY_MODEL_cabaf54cd29045aeadee55bc9278602f","value":"Downloading sentencepiece.bpe.model: 100%"}},"5070b0fa7e3f4d51830270d206b2285e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ae8f5a68b654b41b3520c4ca15f6d63","max":5069051,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b9283f5371a34b97816fe410662cb2d7","value":5069051}},"3d7b993355b144559d16f418b23820d1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_789e4d1471834305b02dc88fac9aef6b","placeholder":"​","style":"IPY_MODEL_28e8b1cdbe9a4edea30cda21ee9d7fcd","value":" 4.83M/4.83M [00:00&lt;00:00, 26.0MB/s]"}},"cad28b1d4b0d4dfeb0b7ca4aa02253b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7de83b91f1394a078b27a898cc2db31a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cabaf54cd29045aeadee55bc9278602f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2ae8f5a68b654b41b3520c4ca15f6d63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9283f5371a34b97816fe410662cb2d7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"789e4d1471834305b02dc88fac9aef6b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28e8b1cdbe9a4edea30cda21ee9d7fcd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b854e0b0a79f429cadfe913385376071":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bcdbea9c95bd4c6aad656ca6683bde15","IPY_MODEL_8436c2b52b9545888ee04221f44d5729","IPY_MODEL_2905a7910d8644a1abbc4bac9283ce4c"],"layout":"IPY_MODEL_950115fa5de94bee965d305b92d1737d"}},"bcdbea9c95bd4c6aad656ca6683bde15":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d36237fa31144cfadabbb75685bd33e","placeholder":"​","style":"IPY_MODEL_5daf3d5081294d908766e4c42294c488","value":"Downloading special_tokens_map.json: 100%"}},"8436c2b52b9545888ee04221f44d5729":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b6e9284b66494ed2b4033641ed142541","max":150,"min":0,"orientation":"horizontal","style":"IPY_MODEL_87ddc03601414ef3bcfdc981d003efe0","value":150}},"2905a7910d8644a1abbc4bac9283ce4c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd8ce73eb6a14422b335342738a6842f","placeholder":"​","style":"IPY_MODEL_f1bd7fb1086b46d3acad8bee6e388d12","value":" 150/150 [00:00&lt;00:00, 4.79kB/s]"}},"950115fa5de94bee965d305b92d1737d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d36237fa31144cfadabbb75685bd33e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5daf3d5081294d908766e4c42294c488":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b6e9284b66494ed2b4033641ed142541":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87ddc03601414ef3bcfdc981d003efe0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dd8ce73eb6a14422b335342738a6842f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1bd7fb1086b46d3acad8bee6e388d12":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"df65016fb89f4ad085092fbf27dd150c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_31b0dc3f66aa4b3797c2067af53d84b6","IPY_MODEL_23dd246841514124b8818bf52efb44f4","IPY_MODEL_e68b02f5a4184636b4051e7348cfb379"],"layout":"IPY_MODEL_4a0999a0f0834426914b05d59e7c0d4c"}},"31b0dc3f66aa4b3797c2067af53d84b6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c712a98f4c9e440699dd1984572f94d0","placeholder":"​","style":"IPY_MODEL_fb5291e362de4989b2ee8f5cea70149e","value":"100%"}},"23dd246841514124b8818bf52efb44f4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9246d2706f8d4786b4439d4de252f6b6","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1b6320f3b022464a8d099f7b9ef8c490","value":1}},"e68b02f5a4184636b4051e7348cfb379":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cbf8a089118f47edbdaaefc06bcf4284","placeholder":"​","style":"IPY_MODEL_b6f1ee057ccc4ceabea22bacb1e5ed08","value":" 1/1 [00:00&lt;00:00,  6.87ba/s]"}},"4a0999a0f0834426914b05d59e7c0d4c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c712a98f4c9e440699dd1984572f94d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb5291e362de4989b2ee8f5cea70149e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9246d2706f8d4786b4439d4de252f6b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b6320f3b022464a8d099f7b9ef8c490":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cbf8a089118f47edbdaaefc06bcf4284":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6f1ee057ccc4ceabea22bacb1e5ed08":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"825fbe76622f433db599f764b87b341f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_780599d793f647cfa8da2ddb9764dddd","IPY_MODEL_a7a83107e4b849cc9b4e248ae60d7001","IPY_MODEL_21c04731744042e48cda1195e18f8243"],"layout":"IPY_MODEL_02f12be3a6854c7ba5c83f4680be8d3c"}},"780599d793f647cfa8da2ddb9764dddd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8de43060d045417399f8e3efc22f9484","placeholder":"​","style":"IPY_MODEL_62072a0b2b9c418fa096887d77aee5b3","value":"100%"}},"a7a83107e4b849cc9b4e248ae60d7001":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5fd36132f0564948bc8b05b9e4337b64","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_77dcd3f89cb946298afe7d977260c66a","value":2}},"21c04731744042e48cda1195e18f8243":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_772ebbf364c44519a34fd5ae446bda66","placeholder":"​","style":"IPY_MODEL_b8a822e4cdb4458288ef5c611d2935c5","value":" 2/2 [00:00&lt;00:00,  4.68ba/s]"}},"02f12be3a6854c7ba5c83f4680be8d3c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8de43060d045417399f8e3efc22f9484":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62072a0b2b9c418fa096887d77aee5b3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5fd36132f0564948bc8b05b9e4337b64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77dcd3f89cb946298afe7d977260c66a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"772ebbf364c44519a34fd5ae446bda66":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8a822e4cdb4458288ef5c611d2935c5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"54d6ba6cb764405987a61d5cd1eeba48":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eb9688c3daf04d7482589f66e2cd4ad7","IPY_MODEL_eed6d26b8aff40e8a4ced18a63b93c5f","IPY_MODEL_cfa2fb8690804e14b57e7f75d0c6575d"],"layout":"IPY_MODEL_a3aba0ebbaa148c8a3c3f24e4a8b9826"}},"eb9688c3daf04d7482589f66e2cd4ad7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d22610fec5c466bb7653357e97e2340","placeholder":"​","style":"IPY_MODEL_51f3885f1d4d4bb9b77eb42264c1d282","value":"Downloading builder script: "}},"eed6d26b8aff40e8a4ced18a63b93c5f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c8504f72bdd4687a5dd567cc935d2b9","max":1705,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8508853fa9cb464ebc600432f5318457","value":1705}},"cfa2fb8690804e14b57e7f75d0c6575d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e21ffb3bd73845a78c13f24c48700d82","placeholder":"​","style":"IPY_MODEL_e1fa9e20de8741d492012c1f8c97d4db","value":" 4.47k/? [00:00&lt;00:00, 122kB/s]"}},"a3aba0ebbaa148c8a3c3f24e4a8b9826":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d22610fec5c466bb7653357e97e2340":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51f3885f1d4d4bb9b77eb42264c1d282":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0c8504f72bdd4687a5dd567cc935d2b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8508853fa9cb464ebc600432f5318457":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e21ffb3bd73845a78c13f24c48700d82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1fa9e20de8741d492012c1f8c97d4db":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ef29ed3d2b5f4153906d42c3bce1ea5a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b4823935b6334fcdb92f7688e4750cfd","IPY_MODEL_fe161e8956e94af28f1236a73062ae2a","IPY_MODEL_6fe1224f862e4ba48494b2577bbf47a4"],"layout":"IPY_MODEL_223c27a2a539445a86459f81aa93fe6b"}},"b4823935b6334fcdb92f7688e4750cfd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e1f9720d9ee42be8f09286fa6f8a001","placeholder":"​","style":"IPY_MODEL_3a663d76cd32419cbe20ffc3478ec2ba","value":"Downloading pytorch_model.bin: 100%"}},"fe161e8956e94af28f1236a73062ae2a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_05d242e4ce2e4d1d9810dcf41e7128ca","max":1112271561,"min":0,"orientation":"horizontal","style":"IPY_MODEL_86a509073e5d4422be8de8524bd34529","value":1112271561}},"6fe1224f862e4ba48494b2577bbf47a4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f7d3591cca7e4b66ace0fa8e83a34362","placeholder":"​","style":"IPY_MODEL_2dc1d7574ac14cf9b13fb7e40752f4c2","value":" 1.04G/1.04G [00:27&lt;00:00, 45.9MB/s]"}},"223c27a2a539445a86459f81aa93fe6b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e1f9720d9ee42be8f09286fa6f8a001":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a663d76cd32419cbe20ffc3478ec2ba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"05d242e4ce2e4d1d9810dcf41e7128ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86a509073e5d4422be8de8524bd34529":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f7d3591cca7e4b66ace0fa8e83a34362":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2dc1d7574ac14cf9b13fb7e40752f4c2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}