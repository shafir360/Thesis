{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pretraining-labelling.ipynb","provenance":[],"mount_file_id":"1OIvNZHsYQJ1YZEHNaM924wtQKIoWSJSe","authorship_tag":"ABX9TyPvuMVq5EVPEcMFh1rM0yvf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ge2NdLKeS7SF","executionInfo":{"status":"ok","timestamp":1660246308043,"user_tz":-60,"elapsed":9132,"user":{"displayName":"S Rahman","userId":"04000762971548563689"}},"outputId":"0347f364-f841-450d-8466-36f753db577f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.21.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.4.0)\n","Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.8.1)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.12.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.7.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.1)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"]}],"source":["!pip install transformers\n","!pip install datasets\n","import pandas as pd\n","import requests\n","import os\n","import re\n","import csv\n","from transformers import pipeline\n","import torch.nn.functional as F\n","from transformers import AutoTokenizer , AutoModelForSequenceClassification\n","import torch\n","import numpy as np\n","import torch\n"]},{"cell_type":"code","source":["from transformers import Trainer\n","from transformers import TrainingArguments\n","#learning_rate = 5e-05\n","#batch_size = 16\n","#eval_batch_size = 4\n","seed = 40\n","#optimizer = Adam \n","#with betas=(0.9,0.999) and epsilon=1e-08\n","adam_beta1 = 0.9\n","adam_beta2 =0.999\n","lr_scheduler_type = \"linear\"\n","num_epochs = 15\n","#args = TrainingArguments(\"test_trainer\",report_to=\"wandb\" ,logging_strategy = \"epoch\",evaluation_strategy=\"epoch\",learning_rate = learning_rate,num_train_epochs = num_epochs,lr_scheduler_type =lr_scheduler_type, adam_beta1 = adam_beta1,adam_beta2 =adam_beta2  )\n","\n","\n","def run_trainer(model_name,out_dir,epoch,batch_size,df_train,df_valid,eval_bool):\n","  df_train = df_train[['text','label']].set_index('text')\n","  df_valid = df_valid[['text','label']].set_index('text')\n","  #display(df_train)\n","  #display(df_valid)\n","\n","  dataset = ds.dataset(pa.Table.from_pandas(df_valid).to_batches())\n","  ### convert to Huggingface dataset\n","  validation_dataset_torch = Dataset(pa.Table.from_pandas(df_valid))\n","\n","  dataset = ds.dataset(pa.Table.from_pandas(df_train).to_batches())\n","  ### convert to Huggingface dataset\n","  training_dataset_torch = Dataset(pa.Table.from_pandas(df_train))\n","\n","  #print(training_dataset_torch)\n","  #print(validation_dataset_torch)\n","\n","  from transformers import AutoTokenizer\n","\n","  tokenizer = AutoTokenizer.from_pretrained(model_name,model_max_length=512)\n","\n","\n","\n","  def tokenize_function(data):\n","      return tokenizer(data['text'], padding=\"max_length\", truncation=True,)\n","\n","\n","  train_dataset = training_dataset_torch.map(tokenize_function, batched=True)\n","  eval_dataset = validation_dataset_torch.map(tokenize_function, batched=True)\n","  print(train_dataset)\n","  print(eval_dataset)\n","\n","  import numpy as np\n","  from datasets import load_metric\n","\n","  metric = load_metric(\"matthews_correlation\")\n","\n","  def compute_metrics(eval_pred):\n","      logits, labels = eval_pred\n","      predictions = np.argmax(logits, axis=-1)\n","      return metric.compute(predictions=predictions, references=labels)\n","\n","\n","  from transformers import AutoModelForSequenceClassification\n","\n","  model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n","  #model.to(device)\n","  args = TrainingArguments(\n","      #'/content/drive/MyDrive/fyp/fyp2/model/model2-supervised/' + f\"{model_name}-finetuned-\",\n","      #'/content/' + f\"{model_name}-finetuned-\",\n","      out_dir,\n","      #report_to=\"wandb\",\n","      overwrite_output_dir = True,\n","      logging_dir = out_dir,\n","      evaluation_strategy = \"epoch\",\n","      logging_strategy = \"epoch\",\n","      #save_strategy = \"NO\",\n","      learning_rate=2.6510704963161386e-06,\n","      per_device_train_batch_size=batch_size,\n","      per_device_eval_batch_size=batch_size,\n","      num_train_epochs=epoch,\n","      weight_decay=0.01,\n","      metric_for_best_model='matthews_correlation',\n","      save_total_limit = 2,\n","      save_strategy = \"epoch\",\n","      load_best_model_at_end = True,\n","      seed = 18\n","      #push_to_hub=True,\n","  )\n","\n","\n","\n","  trainer = Trainer(\n","      model,\n","      args,\n","      train_dataset=train_dataset,\n","      eval_dataset=eval_dataset,\n","      tokenizer=tokenizer,\n","      compute_metrics=compute_metrics\n","  )\n","\n","  #trainer = Trainer(\n","    # model=model,\n","      #args=args,\n","    # train_dataset=train_dataset,\n","    #  eval_dataset=eval_dataset,\n","  #   compute_metrics=compute_metrics,\n","  #)\n","\n","  \n","  if eval_bool:\n","    eval = trainer.evaluate()\n","    #print(\"bob\")\n","    #print(eval)\n","    \n","    # training\n","  else:\n","    train_result = trainer.train() \n","    logs = trainer.state.log_history\n","    # compute train results\n","    metrics = train_result.metrics\n","    max_train_samples = len(train_dataset)\n","    metrics[\"train_samples\"] = min(max_train_samples, len(train_dataset))\n","\n","    # save train results\n","    trainer.log_metrics(\"train\", metrics)\n","    trainer.save_metrics(\"train\", metrics)\n","\n","    # compute evaluation results\n","    metrics = trainer.evaluate()\n","    max_val_samples = len(eval_dataset)\n","    metrics[\"eval_samples\"] = min(max_val_samples, len(eval_dataset))\n","\n","    # save evaluation results\n","    trainer.log_metrics(\"eval\", metrics)\n","    trainer.save_metrics(\"eval\", metrics)\n","    import pickle\n","    save_logs_dir = out_dir\n","    name_logs = \"logs\"\n","    \n","    my_file = save_logs_dir + \"/\" + name_logs + \".p\"\n","    print(\"saving to \",my_file )\n","\n","    pickle.dump( logs, open( my_file, \"wb\" )    ) \n","\n","    ld = pickle.load( open( my_file, \"rb\" ) )\n","\n","\n","    print(logs)\n","    print(logs[2])\n","    print(type(logs))\n","\n","    print(ld)\n","    print(type(ld))\n","    print(logs == ld)\n","    eval = trainer.evaluate()\n","    \n","  import torch\n","  torch.cuda.is_available() \n","  from numba import cuda\n","  del trainer,args\n","  torch.cuda.empty_cache()\n","  #trainer.evaluate()\n","  return eval\n","\n"],"metadata":{"id":"S_XqZAyZ-YB8","executionInfo":{"status":"ok","timestamp":1660246308044,"user_tz":-60,"elapsed":12,"user":{"displayName":"S Rahman","userId":"04000762971548563689"}}},"execution_count":5,"outputs":[]}]}