{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3278,"status":"ok","timestamp":1659837511657,"user":{"displayName":"S Rahman","userId":"04000762971548563689"},"user_tz":-60},"id":"klpNNdQNRAzv","outputId":"be2b186e-9d9f-4b01-897d-5aaa1a78d315"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16179,"status":"ok","timestamp":1659837527821,"user":{"displayName":"S Rahman","userId":"04000762971548563689"},"user_tz":-60},"id":"iX00mr6WfSHG","outputId":"c99abc5c-ddfc-49ab-eda2-4a6b955a9565"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.21.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.4.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.8.1)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.7.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.12.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.6.15)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: GPUtil in /usr/local/lib/python3.7/dist-packages (1.4.0)\n"]},{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f657bd08750>"]},"metadata":{},"execution_count":2}],"source":["!pip install transformers\n","!pip install datasets\n","!pip install sentencepiece\n","!pip install GPUtil\n","import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n","#!pip install wandb\n","import json\n","from transformers import AutoTokenizer\n","from transformers import TFAutoModelForSequenceClassification\n","import tensorflow as tf\n","from tensorflow.keras.losses import SparseCategoricalCrossentropy\n","\n","import numpy as np\n","import pandas as pd\n","\n","\n","import pyarrow as pa\n","import pyarrow.dataset as ds\n","import pandas as pd\n","from datasets import Dataset\n","import torch\n","\n","RANDOM_SEED = 42\n","\n","np.random.seed(RANDOM_SEED)\n","\n","torch.manual_seed(RANDOM_SEED)"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":438,"status":"ok","timestamp":1659837528241,"user":{"displayName":"S Rahman","userId":"04000762971548563689"},"user_tz":-60},"id":"NoSFcYvATZJ_"},"outputs":[],"source":["\n","def ConvertLabel2ModelLabel(label):\n","  if label == 'Positive':\n","    o = 2\n","  elif label == 'Neutral':\n","    o = 1\n","  elif label == 'Negative':\n","    o = 0\n","  elif label == 'spam':\n","    o = 1\n","  else: \n","    print(\" error at ConvertLabel2ModelLabel label is \" , label)\n","    o = np.nan\n","  return o\n","\n","\n","from GPUtil import showUtilization as gpu_usage\n","from numba import cuda\n","\n","def free_gpu_cache():\n","    print(\"Initial GPU Usage\")\n","    gpu_usage()                             \n","\n","    torch.cuda.empty_cache()\n","\n","    cuda.select_device(0)\n","    cuda.close()\n","    cuda.select_device(0)\n","\n","    print(\"GPU Usage after emptying the cache\")\n","    gpu_usage()"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":830},"executionInfo":{"elapsed":2210,"status":"ok","timestamp":1659837530444,"user":{"displayName":"S Rahman","userId":"04000762971548563689"},"user_tz":-60},"id":"0Yk0sHM_ff68","outputId":"e515f8a1-029a-4807-929e-579efdf0867b"},"outputs":[{"output_type":"display_data","data":{"text/plain":["      Unnamed: 0                                               text     label  \\\n","0            339  –ö—Ä–∏–ø—Ç–æ–í–µ—Å—Ç–∏ BTC ü§ò  Blockasset Taps Well-Known ...  Positive   \n","1            747  Full thanks to  as they have analysed this Bit...   Neutral   \n","2            301  __crypto _tw  üî• SanjiInu üî•  üí• KYC, CHARITY, NF...   Neutral   \n","3           1743  $btc btc health check! No custom death cross; ...   Neutral   \n","4           1108  44 üè¶FTX | BTC PERP  ü¶ã If you have trouble imag...   Neutral   \n","...          ...                                                ...       ...   \n","2785         683  This will be very useful in the future because...  Positive   \n","2786        1451  And without Bitcoin Maxies hyping Bitcoin , th...  Positive   \n","2787        1106  11 IST   88.724  37996.605 ‚Çø  3371120.946  253...  Positive   \n","2788        1787                     Bitcoin is Liberation Network.  Positive   \n","2789         344  bitcoin is the best MONEY in the history of ma...   Neutral   \n","\n","             source quality  \n","0      new_turk_low     low  \n","1     new_turk_high    high  \n","2       self_manual    high  \n","3      new_turk_low     low  \n","4      new_turk_low     low  \n","...             ...     ...  \n","2785   new_turk_low     low  \n","2786   new_turk_low     low  \n","2787   new_turk_low     low  \n","2788   new_turk_low     low  \n","2789   new_turk_low     low  \n","\n","[2790 rows x 5 columns]"],"text/html":["\n","  <div id=\"df-0f7f82cd-7cdc-419d-9899-1da044d48035\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>text</th>\n","      <th>label</th>\n","      <th>source</th>\n","      <th>quality</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>339</td>\n","      <td>–ö—Ä–∏–ø—Ç–æ–í–µ—Å—Ç–∏ BTC ü§ò  Blockasset Taps Well-Known ...</td>\n","      <td>Positive</td>\n","      <td>new_turk_low</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>747</td>\n","      <td>Full thanks to  as they have analysed this Bit...</td>\n","      <td>Neutral</td>\n","      <td>new_turk_high</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>301</td>\n","      <td>__crypto _tw  üî• SanjiInu üî•  üí• KYC, CHARITY, NF...</td>\n","      <td>Neutral</td>\n","      <td>self_manual</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1743</td>\n","      <td>$btc btc health check! No custom death cross; ...</td>\n","      <td>Neutral</td>\n","      <td>new_turk_low</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1108</td>\n","      <td>44 üè¶FTX | BTC PERP  ü¶ã If you have trouble imag...</td>\n","      <td>Neutral</td>\n","      <td>new_turk_low</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2785</th>\n","      <td>683</td>\n","      <td>This will be very useful in the future because...</td>\n","      <td>Positive</td>\n","      <td>new_turk_low</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>2786</th>\n","      <td>1451</td>\n","      <td>And without Bitcoin Maxies hyping Bitcoin , th...</td>\n","      <td>Positive</td>\n","      <td>new_turk_low</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>2787</th>\n","      <td>1106</td>\n","      <td>11 IST   88.724  37996.605 ‚Çø  3371120.946  253...</td>\n","      <td>Positive</td>\n","      <td>new_turk_low</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>2788</th>\n","      <td>1787</td>\n","      <td>Bitcoin is Liberation Network.</td>\n","      <td>Positive</td>\n","      <td>new_turk_low</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>2789</th>\n","      <td>344</td>\n","      <td>bitcoin is the best MONEY in the history of ma...</td>\n","      <td>Neutral</td>\n","      <td>new_turk_low</td>\n","      <td>low</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2790 rows √ó 5 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0f7f82cd-7cdc-419d-9899-1da044d48035')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0f7f82cd-7cdc-419d-9899-1da044d48035 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0f7f82cd-7cdc-419d-9899-1da044d48035');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["      Unnamed: 0                                               text     label  \\\n","0             71  Full thanks to  as they have analysed this Bit...  Positive   \n","1            266             Typing mistake for Satoshi not bitcoin   Neutral   \n","2            410  Saitama SaitamaWolfPack SaitamaInu SaitaMask $...   Neutral   \n","3            333  100%, the nuclear industry has no idea what is...   Neutral   \n","4            401  airdrop Airdrops Crypto BSC DeFi Polygon Bitco...   Neutral   \n","...          ...                                                ...       ...   \n","1190         171  This is a very good project so don't miss to j...  Positive   \n","1191         319        Whoever didn‚Äôt panic sell we made it ü§ùüéâ BTC  Positive   \n","1192         896  To know more about IPOs and Unlisted shares, c...   Neutral   \n","1193         425  Soon to the moon üåú   Unitycol $Unity Unityprot...  Positive   \n","1194         153  Bitcoin Price     $48665.02     $37554.85     ...   Neutral   \n","\n","                source quality  \n","0     incomplete_valid    high  \n","1     incomplete_valid    high  \n","2     incomplete_valid    high  \n","3        new_turk_high    high  \n","4          self_manual    high  \n","...                ...     ...  \n","1190     new_turk_high    high  \n","1191     new_turk_high    high  \n","1192     new_turk_high    high  \n","1193  incomplete_valid    high  \n","1194     new_turk_high    high  \n","\n","[1195 rows x 5 columns]"],"text/html":["\n","  <div id=\"df-1242f0dc-05c4-4d25-b77e-6a0d96301b17\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>text</th>\n","      <th>label</th>\n","      <th>source</th>\n","      <th>quality</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>71</td>\n","      <td>Full thanks to  as they have analysed this Bit...</td>\n","      <td>Positive</td>\n","      <td>incomplete_valid</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>266</td>\n","      <td>Typing mistake for Satoshi not bitcoin</td>\n","      <td>Neutral</td>\n","      <td>incomplete_valid</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>410</td>\n","      <td>Saitama SaitamaWolfPack SaitamaInu SaitaMask $...</td>\n","      <td>Neutral</td>\n","      <td>incomplete_valid</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>333</td>\n","      <td>100%, the nuclear industry has no idea what is...</td>\n","      <td>Neutral</td>\n","      <td>new_turk_high</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>401</td>\n","      <td>airdrop Airdrops Crypto BSC DeFi Polygon Bitco...</td>\n","      <td>Neutral</td>\n","      <td>self_manual</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1190</th>\n","      <td>171</td>\n","      <td>This is a very good project so don't miss to j...</td>\n","      <td>Positive</td>\n","      <td>new_turk_high</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>1191</th>\n","      <td>319</td>\n","      <td>Whoever didn‚Äôt panic sell we made it ü§ùüéâ BTC</td>\n","      <td>Positive</td>\n","      <td>new_turk_high</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>1192</th>\n","      <td>896</td>\n","      <td>To know more about IPOs and Unlisted shares, c...</td>\n","      <td>Neutral</td>\n","      <td>new_turk_high</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>1193</th>\n","      <td>425</td>\n","      <td>Soon to the moon üåú   Unitycol $Unity Unityprot...</td>\n","      <td>Positive</td>\n","      <td>incomplete_valid</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>1194</th>\n","      <td>153</td>\n","      <td>Bitcoin Price     $48665.02     $37554.85     ...</td>\n","      <td>Neutral</td>\n","      <td>new_turk_high</td>\n","      <td>high</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1195 rows √ó 5 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1242f0dc-05c4-4d25-b77e-6a0d96301b17')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1242f0dc-05c4-4d25-b77e-6a0d96301b17 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1242f0dc-05c4-4d25-b77e-6a0d96301b17');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}],"source":["train_path = '/content/drive/MyDrive/fyp/fyp2/final models and datasets/dataset/dataset_new_with_self_label_final_5.0:3.0:3.0/train_dataset.csv'\n","valid_path = '/content/drive/MyDrive/fyp/fyp2/final models and datasets/dataset/dataset_new_with_self_label_final_5.0:3.0:3.0/valid_dataset.csv'\n","\n","train_path = '/content/drive/MyDrive/fyp/fyp2/final models and datasets/dataset/dataset_new_with_self_label_3.0:4.0:4.0/train_dataset.csv'\n","valid_path ='/content/drive/MyDrive/fyp/fyp2/final models and datasets/dataset/dataset_new_with_self_label_3.0:4.0:4.0/valid_dataset.csv'\n","\n","model_name = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n","#out = '/content/drive/MyDrive/fyp/fyp2/final models and datasets/sva_eval'\n","out = \"/content/temp\"\n","\n","import shutil\n","\n","if not os.path.exists(out):\n","  \n","  # Create a new directory because it does not exist \n","  os.makedirs(out)\n","else:\n","  shutil.rmtree(out)\n","#shutil.rmtree(out)\n","\n","name_of_text_column = \"text\"\n","#hyperparameter_tuning = True\n","reduce_ = False\n","num_hyper_trails = 3\n","hyper_size = 32\n","epoch = 12\n","train_type = \"mixed\"\n","\n","\n","df_train = pd.read_csv(train_path)\n","\n","if train_type == \"low\":\n","  df_train = df_train[df_train['quality'] == \"low\"]\n","elif train_type == \"high\":\n","  df_train = df_train[df_train['quality'] == \"high\"]\n","\n","\n","df_valid = pd.read_csv(valid_path)\n","\n","display(df_train)\n","display(df_valid)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":830},"executionInfo":{"elapsed":68,"status":"ok","timestamp":1659837530445,"user":{"displayName":"S Rahman","userId":"04000762971548563689"},"user_tz":-60},"id":"GoIvErk1T_LX","outputId":"12d46236-bddd-4a4c-ca6c-a870cd30f941"},"outputs":[{"output_type":"display_data","data":{"text/plain":["                                                   text  label\n","0     –ö—Ä–∏–ø—Ç–æ–í–µ—Å—Ç–∏ BTC ü§ò  Blockasset Taps Well-Known ...      2\n","1     Full thanks to  as they have analysed this Bit...      1\n","2     __crypto _tw  üî• SanjiInu üî•  üí• KYC, CHARITY, NF...      1\n","3     $btc btc health check! No custom death cross; ...      1\n","4     44 üè¶FTX | BTC PERP  ü¶ã If you have trouble imag...      1\n","...                                                 ...    ...\n","2785  This will be very useful in the future because...      2\n","2786  And without Bitcoin Maxies hyping Bitcoin , th...      2\n","2787  11 IST   88.724  37996.605 ‚Çø  3371120.946  253...      2\n","2788                     Bitcoin is Liberation Network.      2\n","2789  bitcoin is the best MONEY in the history of ma...      1\n","\n","[2790 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-78a42fde-e96e-4b63-a609-192eb81e5c81\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>–ö—Ä–∏–ø—Ç–æ–í–µ—Å—Ç–∏ BTC ü§ò  Blockasset Taps Well-Known ...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Full thanks to  as they have analysed this Bit...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>__crypto _tw  üî• SanjiInu üî•  üí• KYC, CHARITY, NF...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>$btc btc health check! No custom death cross; ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>44 üè¶FTX | BTC PERP  ü¶ã If you have trouble imag...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2785</th>\n","      <td>This will be very useful in the future because...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2786</th>\n","      <td>And without Bitcoin Maxies hyping Bitcoin , th...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2787</th>\n","      <td>11 IST   88.724  37996.605 ‚Çø  3371120.946  253...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2788</th>\n","      <td>Bitcoin is Liberation Network.</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2789</th>\n","      <td>bitcoin is the best MONEY in the history of ma...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2790 rows √ó 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-78a42fde-e96e-4b63-a609-192eb81e5c81')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-78a42fde-e96e-4b63-a609-192eb81e5c81 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-78a42fde-e96e-4b63-a609-192eb81e5c81');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["                                                   text  label\n","0     Full thanks to  as they have analysed this Bit...      2\n","1                Typing mistake for Satoshi not bitcoin      1\n","2     Saitama SaitamaWolfPack SaitamaInu SaitaMask $...      1\n","3     100%, the nuclear industry has no idea what is...      1\n","4     airdrop Airdrops Crypto BSC DeFi Polygon Bitco...      1\n","...                                                 ...    ...\n","1190  This is a very good project so don't miss to j...      2\n","1191        Whoever didn‚Äôt panic sell we made it ü§ùüéâ BTC      2\n","1192  To know more about IPOs and Unlisted shares, c...      1\n","1193  Soon to the moon üåú   Unitycol $Unity Unityprot...      2\n","1194  Bitcoin Price     $48665.02     $37554.85     ...      1\n","\n","[1195 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-9fe0caba-260b-478f-a4b2-cf1684f1a294\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Full thanks to  as they have analysed this Bit...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Typing mistake for Satoshi not bitcoin</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Saitama SaitamaWolfPack SaitamaInu SaitaMask $...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>100%, the nuclear industry has no idea what is...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>airdrop Airdrops Crypto BSC DeFi Polygon Bitco...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1190</th>\n","      <td>This is a very good project so don't miss to j...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1191</th>\n","      <td>Whoever didn‚Äôt panic sell we made it ü§ùüéâ BTC</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1192</th>\n","      <td>To know more about IPOs and Unlisted shares, c...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1193</th>\n","      <td>Soon to the moon üåú   Unitycol $Unity Unityprot...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1194</th>\n","      <td>Bitcoin Price     $48665.02     $37554.85     ...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1195 rows √ó 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9fe0caba-260b-478f-a4b2-cf1684f1a294')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9fe0caba-260b-478f-a4b2-cf1684f1a294 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9fe0caba-260b-478f-a4b2-cf1684f1a294');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}],"source":["df_train['label'] = df_train['label'].apply(ConvertLabel2ModelLabel)\n","df_valid['label'] = df_valid['label'].apply(ConvertLabel2ModelLabel)\n","\n","df_train = df_train[[\"text\",\"label\"]]\n","df_valid = df_valid[[\"text\",\"label\"]]\n","display(df_train)\n","display(df_valid)\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":66,"status":"ok","timestamp":1659837530446,"user":{"displayName":"S Rahman","userId":"04000762971548563689"},"user_tz":-60},"id":"9Xi5yBzDgJrk","outputId":"f21d4a20-9f48-4308-fce9-4782f7458e0b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset({\n","    features: ['text', 'label'],\n","    num_rows: 2790\n","})\n","Dataset({\n","    features: ['text', 'label'],\n","    num_rows: 1195\n","})\n"]}],"source":["if reduce_:\n","  df_train = df_train[0:200]\n","\n","\n","\n","dataset = ds.dataset(pa.Table.from_pandas(df_valid).to_batches())\n","### convert to Huggingface dataset\n","validation_dataset_torch = Dataset(pa.Table.from_pandas(df_valid))\n","\n","dataset = ds.dataset(pa.Table.from_pandas(df_train).to_batches())\n","### convert to Huggingface dataset\n","training_dataset_torch = Dataset(pa.Table.from_pandas(df_train))\n","\n","\n","print(training_dataset_torch)\n","print(validation_dataset_torch)\n"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":39,"status":"ok","timestamp":1659837530446,"user":{"displayName":"S Rahman","userId":"04000762971548563689"},"user_tz":-60},"id":"aNeojj49TM9s"},"outputs":[],"source":["\n","\n","def balanced_df(df_):\n","  #print(df.shape[0])\n","  df = df_.copy()\n","  df = df[['text','label']]\n","\n","  df_pos = df[df['label'] == 2].sample(frac=1).reset_index(drop=True)\n","  df_neg = df[df['label'] == 0].sample(frac=1).reset_index(drop=True)\n","  df_neu = df[df['label'] == 1 ].sample(frac=1).reset_index(drop=True)\n","  \n","\n","  pos = df_pos.shape[0]\n","  a = pos\n","  #print(a)\n","  neg = df_neg.shape[0]\n","  b = neg\n","  #print(b)\n","  neu = df_neu.shape[0]\n","  c = neu\n","  #print(c)\n","  #print(a+b+c)\n","  if a < b and a < c :\n","    smallest = a\n","  if b < a and b < c :\n","    smallest = b\n","  if c < a and c < b :\n","    smallest = c\n","\n","  smallest = int(smallest/2)\n","\n","  li_test = [df_pos[0:smallest],df_neg[0:smallest],df_neu[0:smallest]]\n","  li_valid = [df_pos[smallest:smallest*2],df_neg[smallest:smallest*2],df_neu[smallest:smallest*2]]\n","  #print(\"check\")\n","  #display(df_pos[0:smallest])\n","  unused_li = [df_pos[smallest*2:],df_neg[smallest*2:],df_neu[smallest*2:]]\n","  \n","\n","  return  pd.concat(li_valid,axis=0).sample(frac=1).reset_index(drop=True),pd.concat(li_test,axis=0).sample(frac=1).reset_index(drop=True), pd.concat(unused_li,axis=0).sample(frac=1).reset_index(drop=True)\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":5006,"status":"ok","timestamp":1659837535414,"user":{"displayName":"S Rahman","userId":"04000762971548563689"},"user_tz":-60},"id":"y0aboBlPf3Fs"},"outputs":[],"source":["from transformers import AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_name,model_max_length=512)\n","\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":237,"referenced_widgets":["a128df2e7bc74089952d564327295a2c","c3da4af1933241fca873e986133d6ce7","ae0878c1f7da49fdb302e2f4cbf6099d","9da02d789a5549139b9fef16d7e71f87","acf390c9cfed43dc84d8f74080ba3c04","186dfca8c19a4104bb2acb8607704f48","d6e45edb554040ea8bf90f1832304fb1","eeb247ecde1f4e4cafb6fa5ecffd5932","4476fe01f8a34b4ba36ff67238974b10","74753b649c7b43c7a8d4edc640b79b9a","4df0837afa994b53a60596d81f7529bd","daba5528bc964e7da2b988db7dee6e4e","825b03ef0491471ba5df15beb464e9b0","70b4c66e41d14c1e8f3827636d12b440","30c00b93f34849d3a39ef00312b676f4","6e29591aaa334273a4922399185e6633","7a1be35f747b425fb78d12e802f3e8cf","8799f18802aa4c309f5383ae3acab966","fafb8310b8ff4d5e9ce6e3c7ac8d5d4a","262dbffa48fe47ac838ae2edafcfc81c","6e5106a321ce41e8a1d331b212fcdb3a","5a42086c962f45eda435ae37ffeefe5f"]},"executionInfo":{"elapsed":870,"status":"ok","timestamp":1659837536245,"user":{"displayName":"S Rahman","userId":"04000762971548563689"},"user_tz":-60},"id":"sk0C5LiPh7lh","outputId":"21e7bfc6-64dd-4cc1-f89b-3c61d8d909c6"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'datasets.arrow_dataset.Dataset'>\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/3 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a128df2e7bc74089952d564327295a2c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"daba5528bc964e7da2b988db7dee6e4e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset({\n","    features: ['text', 'label', 'input_ids', 'attention_mask'],\n","    num_rows: 2790\n","})\n","Dataset({\n","    features: ['text', 'label', 'input_ids', 'attention_mask'],\n","    num_rows: 1195\n","})\n"]}],"source":["def tokenize_function(data):\n","    return tokenizer(data['text'], padding=\"max_length\", truncation=True,)\n","\n","print(type(training_dataset_torch))\n","train_dataset = training_dataset_torch.map(tokenize_function, batched=True)\n","eval_dataset = validation_dataset_torch.map(tokenize_function, batched=True)\n","\n","print(train_dataset)\n","print(eval_dataset)\n","\n","\n"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":504,"status":"ok","timestamp":1659837536734,"user":{"displayName":"S Rahman","userId":"04000762971548563689"},"user_tz":-60},"id":"wLtrOH4w_Unn"},"outputs":[],"source":["import numpy as np\n","from datasets import load_metric\n","\n","metric = load_metric(\"matthews_correlation\")\n","\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=-1)\n","    return metric.compute(predictions=predictions, references=labels)\n"]},{"cell_type":"code","execution_count":11,"metadata":{"collapsed":true,"executionInfo":{"elapsed":4218,"status":"ok","timestamp":1659837540942,"user":{"displayName":"S Rahman","userId":"04000762971548563689"},"user_tz":-60},"id":"FomHyQrikzKi"},"outputs":[],"source":["from transformers import AutoModelForSequenceClassification\n","\n","model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n","#model.to(device)"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":1777802,"status":"ok","timestamp":1659839318724,"user":{"displayName":"S Rahman","userId":"04000762971548563689"},"user_tz":-60},"id":"SG6S7inA_RKv","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"813db4c5-b48a-45d2-e622-662981574875"},"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the training set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 2790\n","  Num Epochs = 12\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 4188\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='4188' max='4188' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [4188/4188 29:19, Epoch 12/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Matthews Correlation</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.930500</td>\n","      <td>0.769836</td>\n","      <td>0.454717</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.846600</td>\n","      <td>0.741414</td>\n","      <td>0.440205</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.793100</td>\n","      <td>0.766427</td>\n","      <td>0.279496</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.759600</td>\n","      <td>0.715582</td>\n","      <td>0.523058</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.710900</td>\n","      <td>0.747925</td>\n","      <td>0.498481</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.682300</td>\n","      <td>0.748851</td>\n","      <td>0.457507</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.647800</td>\n","      <td>0.785086</td>\n","      <td>0.486181</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.625500</td>\n","      <td>0.798319</td>\n","      <td>0.392011</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.596200</td>\n","      <td>0.797859</td>\n","      <td>0.455014</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.585400</td>\n","      <td>0.823031</td>\n","      <td>0.488834</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.569400</td>\n","      <td>0.814843</td>\n","      <td>0.458473</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.555800</td>\n","      <td>0.818479</td>\n","      <td>0.500973</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 8\n","Saving model checkpoint to /content/temp/checkpoint-349\n","Configuration saved in /content/temp/checkpoint-349/config.json\n","Model weights saved in /content/temp/checkpoint-349/pytorch_model.bin\n","tokenizer config file saved in /content/temp/checkpoint-349/tokenizer_config.json\n","Special tokens file saved in /content/temp/checkpoint-349/special_tokens_map.json\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 8\n","Saving model checkpoint to /content/temp/checkpoint-698\n","Configuration saved in /content/temp/checkpoint-698/config.json\n","Model weights saved in /content/temp/checkpoint-698/pytorch_model.bin\n","tokenizer config file saved in /content/temp/checkpoint-698/tokenizer_config.json\n","Special tokens file saved in /content/temp/checkpoint-698/special_tokens_map.json\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 8\n","Saving model checkpoint to /content/temp/checkpoint-1047\n","Configuration saved in /content/temp/checkpoint-1047/config.json\n","Model weights saved in /content/temp/checkpoint-1047/pytorch_model.bin\n","tokenizer config file saved in /content/temp/checkpoint-1047/tokenizer_config.json\n","Special tokens file saved in /content/temp/checkpoint-1047/special_tokens_map.json\n","Deleting older checkpoint [/content/temp/checkpoint-698] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 8\n","Saving model checkpoint to /content/temp/checkpoint-1396\n","Configuration saved in /content/temp/checkpoint-1396/config.json\n","Model weights saved in /content/temp/checkpoint-1396/pytorch_model.bin\n","tokenizer config file saved in /content/temp/checkpoint-1396/tokenizer_config.json\n","Special tokens file saved in /content/temp/checkpoint-1396/special_tokens_map.json\n","Deleting older checkpoint [/content/temp/checkpoint-349] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 8\n","Saving model checkpoint to /content/temp/checkpoint-1745\n","Configuration saved in /content/temp/checkpoint-1745/config.json\n","Model weights saved in /content/temp/checkpoint-1745/pytorch_model.bin\n","tokenizer config file saved in /content/temp/checkpoint-1745/tokenizer_config.json\n","Special tokens file saved in /content/temp/checkpoint-1745/special_tokens_map.json\n","Deleting older checkpoint [/content/temp/checkpoint-1047] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 8\n","Saving model checkpoint to /content/temp/checkpoint-2094\n","Configuration saved in /content/temp/checkpoint-2094/config.json\n","Model weights saved in /content/temp/checkpoint-2094/pytorch_model.bin\n","tokenizer config file saved in /content/temp/checkpoint-2094/tokenizer_config.json\n","Special tokens file saved in /content/temp/checkpoint-2094/special_tokens_map.json\n","Deleting older checkpoint [/content/temp/checkpoint-1745] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 8\n","Saving model checkpoint to /content/temp/checkpoint-2443\n","Configuration saved in /content/temp/checkpoint-2443/config.json\n","Model weights saved in /content/temp/checkpoint-2443/pytorch_model.bin\n","tokenizer config file saved in /content/temp/checkpoint-2443/tokenizer_config.json\n","Special tokens file saved in /content/temp/checkpoint-2443/special_tokens_map.json\n","Deleting older checkpoint [/content/temp/checkpoint-2094] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 8\n","Saving model checkpoint to /content/temp/checkpoint-2792\n","Configuration saved in /content/temp/checkpoint-2792/config.json\n","Model weights saved in /content/temp/checkpoint-2792/pytorch_model.bin\n","tokenizer config file saved in /content/temp/checkpoint-2792/tokenizer_config.json\n","Special tokens file saved in /content/temp/checkpoint-2792/special_tokens_map.json\n","Deleting older checkpoint [/content/temp/checkpoint-2443] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 8\n","Saving model checkpoint to /content/temp/checkpoint-3141\n","Configuration saved in /content/temp/checkpoint-3141/config.json\n","Model weights saved in /content/temp/checkpoint-3141/pytorch_model.bin\n","tokenizer config file saved in /content/temp/checkpoint-3141/tokenizer_config.json\n","Special tokens file saved in /content/temp/checkpoint-3141/special_tokens_map.json\n","Deleting older checkpoint [/content/temp/checkpoint-2792] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 8\n","Saving model checkpoint to /content/temp/checkpoint-3490\n","Configuration saved in /content/temp/checkpoint-3490/config.json\n","Model weights saved in /content/temp/checkpoint-3490/pytorch_model.bin\n","tokenizer config file saved in /content/temp/checkpoint-3490/tokenizer_config.json\n","Special tokens file saved in /content/temp/checkpoint-3490/special_tokens_map.json\n","Deleting older checkpoint [/content/temp/checkpoint-3141] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 8\n","Saving model checkpoint to /content/temp/checkpoint-3839\n","Configuration saved in /content/temp/checkpoint-3839/config.json\n","Model weights saved in /content/temp/checkpoint-3839/pytorch_model.bin\n","tokenizer config file saved in /content/temp/checkpoint-3839/tokenizer_config.json\n","Special tokens file saved in /content/temp/checkpoint-3839/special_tokens_map.json\n","Deleting older checkpoint [/content/temp/checkpoint-3490] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 8\n","Saving model checkpoint to /content/temp/checkpoint-4188\n","Configuration saved in /content/temp/checkpoint-4188/config.json\n","Model weights saved in /content/temp/checkpoint-4188/pytorch_model.bin\n","tokenizer config file saved in /content/temp/checkpoint-4188/tokenizer_config.json\n","Special tokens file saved in /content/temp/checkpoint-4188/special_tokens_map.json\n","Deleting older checkpoint [/content/temp/checkpoint-3839] due to args.save_total_limit\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/temp/checkpoint-1396 (score: 0.5230578028869062).\n","The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1195\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["***** train metrics *****\n","  epoch                    =       12.0\n","  total_flos               =  8204055GF\n","  train_loss               =     0.6919\n","  train_runtime            = 0:29:20.99\n","  train_samples            =       2790\n","  train_samples_per_second =     19.012\n","  train_steps_per_second   =      2.378\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [150/150 00:14]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["***** eval metrics *****\n","  epoch                     =       12.0\n","  eval_loss                 =     0.7156\n","  eval_matthews_correlation =     0.5231\n","  eval_runtime              = 0:00:14.35\n","  eval_samples              =       1195\n","  eval_samples_per_second   =     83.259\n","  eval_steps_per_second     =     10.451\n","savint to  /content/temp/logs.p\n","[{'loss': 0.9305, 'learning_rate': 2.43014795495646e-06, 'epoch': 1.0, 'step': 349}, {'eval_loss': 0.7698359489440918, 'eval_matthews_correlation': 0.4547170090756245, 'eval_runtime': 14.3223, 'eval_samples_per_second': 83.436, 'eval_steps_per_second': 10.473, 'epoch': 1.0, 'step': 349}, {'loss': 0.8466, 'learning_rate': 2.2092254135967823e-06, 'epoch': 2.0, 'step': 698}, {'eval_loss': 0.7414141893386841, 'eval_matthews_correlation': 0.4402048153140311, 'eval_runtime': 14.2978, 'eval_samples_per_second': 83.58, 'eval_steps_per_second': 10.491, 'epoch': 2.0, 'step': 698}, {'loss': 0.7931, 'learning_rate': 1.988302872237104e-06, 'epoch': 3.0, 'step': 1047}, {'eval_loss': 0.766427218914032, 'eval_matthews_correlation': 0.2794959446290071, 'eval_runtime': 14.3389, 'eval_samples_per_second': 83.34, 'eval_steps_per_second': 10.461, 'epoch': 3.0, 'step': 1047}, {'loss': 0.7596, 'learning_rate': 1.7673803308774256e-06, 'epoch': 4.0, 'step': 1396}, {'eval_loss': 0.7155819535255432, 'eval_matthews_correlation': 0.5230578028869062, 'eval_runtime': 14.3144, 'eval_samples_per_second': 83.482, 'eval_steps_per_second': 10.479, 'epoch': 4.0, 'step': 1396}, {'loss': 0.7109, 'learning_rate': 1.5464577895177476e-06, 'epoch': 5.0, 'step': 1745}, {'eval_loss': 0.7479246258735657, 'eval_matthews_correlation': 0.4984811003664336, 'eval_runtime': 14.293, 'eval_samples_per_second': 83.607, 'eval_steps_per_second': 10.495, 'epoch': 5.0, 'step': 1745}, {'loss': 0.6823, 'learning_rate': 1.3255352481580693e-06, 'epoch': 6.0, 'step': 2094}, {'eval_loss': 0.7488508820533752, 'eval_matthews_correlation': 0.4575070119785073, 'eval_runtime': 14.2867, 'eval_samples_per_second': 83.645, 'eval_steps_per_second': 10.499, 'epoch': 6.0, 'step': 2094}, {'loss': 0.6478, 'learning_rate': 1.1046127067983911e-06, 'epoch': 7.0, 'step': 2443}, {'eval_loss': 0.7850855588912964, 'eval_matthews_correlation': 0.48618104846573057, 'eval_runtime': 14.3023, 'eval_samples_per_second': 83.553, 'eval_steps_per_second': 10.488, 'epoch': 7.0, 'step': 2443}, {'loss': 0.6255, 'learning_rate': 8.836901654387128e-07, 'epoch': 8.0, 'step': 2792}, {'eval_loss': 0.7983193397521973, 'eval_matthews_correlation': 0.39201105749957305, 'eval_runtime': 14.2606, 'eval_samples_per_second': 83.797, 'eval_steps_per_second': 10.519, 'epoch': 8.0, 'step': 2792}, {'loss': 0.5962, 'learning_rate': 6.627676240790346e-07, 'epoch': 9.0, 'step': 3141}, {'eval_loss': 0.7978585362434387, 'eval_matthews_correlation': 0.45501369610129005, 'eval_runtime': 14.3474, 'eval_samples_per_second': 83.291, 'eval_steps_per_second': 10.455, 'epoch': 9.0, 'step': 3141}, {'loss': 0.5854, 'learning_rate': 4.418450827193564e-07, 'epoch': 10.0, 'step': 3490}, {'eval_loss': 0.8230310678482056, 'eval_matthews_correlation': 0.4888339097553538, 'eval_runtime': 14.2779, 'eval_samples_per_second': 83.696, 'eval_steps_per_second': 10.506, 'epoch': 10.0, 'step': 3490}, {'loss': 0.5694, 'learning_rate': 2.209225413596782e-07, 'epoch': 11.0, 'step': 3839}, {'eval_loss': 0.8148431181907654, 'eval_matthews_correlation': 0.45847342180999456, 'eval_runtime': 14.3712, 'eval_samples_per_second': 83.152, 'eval_steps_per_second': 10.438, 'epoch': 11.0, 'step': 3839}, {'loss': 0.5558, 'learning_rate': 0.0, 'epoch': 12.0, 'step': 4188}, {'eval_loss': 0.8184791803359985, 'eval_matthews_correlation': 0.5009729973559511, 'eval_runtime': 14.2947, 'eval_samples_per_second': 83.597, 'eval_steps_per_second': 10.493, 'epoch': 12.0, 'step': 4188}, {'train_runtime': 1760.9942, 'train_samples_per_second': 19.012, 'train_steps_per_second': 2.378, 'total_flos': 8809037225533440.0, 'train_loss': 0.6919248666553807, 'epoch': 12.0, 'step': 4188}, {'eval_loss': 0.7155819535255432, 'eval_matthews_correlation': 0.5230578028869062, 'eval_runtime': 14.3528, 'eval_samples_per_second': 83.259, 'eval_steps_per_second': 10.451, 'epoch': 12.0, 'step': 4188}]\n","{'loss': 0.8466, 'learning_rate': 2.2092254135967823e-06, 'epoch': 2.0, 'step': 698}\n","<class 'list'>\n","[{'loss': 0.9305, 'learning_rate': 2.43014795495646e-06, 'epoch': 1.0, 'step': 349}, {'eval_loss': 0.7698359489440918, 'eval_matthews_correlation': 0.4547170090756245, 'eval_runtime': 14.3223, 'eval_samples_per_second': 83.436, 'eval_steps_per_second': 10.473, 'epoch': 1.0, 'step': 349}, {'loss': 0.8466, 'learning_rate': 2.2092254135967823e-06, 'epoch': 2.0, 'step': 698}, {'eval_loss': 0.7414141893386841, 'eval_matthews_correlation': 0.4402048153140311, 'eval_runtime': 14.2978, 'eval_samples_per_second': 83.58, 'eval_steps_per_second': 10.491, 'epoch': 2.0, 'step': 698}, {'loss': 0.7931, 'learning_rate': 1.988302872237104e-06, 'epoch': 3.0, 'step': 1047}, {'eval_loss': 0.766427218914032, 'eval_matthews_correlation': 0.2794959446290071, 'eval_runtime': 14.3389, 'eval_samples_per_second': 83.34, 'eval_steps_per_second': 10.461, 'epoch': 3.0, 'step': 1047}, {'loss': 0.7596, 'learning_rate': 1.7673803308774256e-06, 'epoch': 4.0, 'step': 1396}, {'eval_loss': 0.7155819535255432, 'eval_matthews_correlation': 0.5230578028869062, 'eval_runtime': 14.3144, 'eval_samples_per_second': 83.482, 'eval_steps_per_second': 10.479, 'epoch': 4.0, 'step': 1396}, {'loss': 0.7109, 'learning_rate': 1.5464577895177476e-06, 'epoch': 5.0, 'step': 1745}, {'eval_loss': 0.7479246258735657, 'eval_matthews_correlation': 0.4984811003664336, 'eval_runtime': 14.293, 'eval_samples_per_second': 83.607, 'eval_steps_per_second': 10.495, 'epoch': 5.0, 'step': 1745}, {'loss': 0.6823, 'learning_rate': 1.3255352481580693e-06, 'epoch': 6.0, 'step': 2094}, {'eval_loss': 0.7488508820533752, 'eval_matthews_correlation': 0.4575070119785073, 'eval_runtime': 14.2867, 'eval_samples_per_second': 83.645, 'eval_steps_per_second': 10.499, 'epoch': 6.0, 'step': 2094}, {'loss': 0.6478, 'learning_rate': 1.1046127067983911e-06, 'epoch': 7.0, 'step': 2443}, {'eval_loss': 0.7850855588912964, 'eval_matthews_correlation': 0.48618104846573057, 'eval_runtime': 14.3023, 'eval_samples_per_second': 83.553, 'eval_steps_per_second': 10.488, 'epoch': 7.0, 'step': 2443}, {'loss': 0.6255, 'learning_rate': 8.836901654387128e-07, 'epoch': 8.0, 'step': 2792}, {'eval_loss': 0.7983193397521973, 'eval_matthews_correlation': 0.39201105749957305, 'eval_runtime': 14.2606, 'eval_samples_per_second': 83.797, 'eval_steps_per_second': 10.519, 'epoch': 8.0, 'step': 2792}, {'loss': 0.5962, 'learning_rate': 6.627676240790346e-07, 'epoch': 9.0, 'step': 3141}, {'eval_loss': 0.7978585362434387, 'eval_matthews_correlation': 0.45501369610129005, 'eval_runtime': 14.3474, 'eval_samples_per_second': 83.291, 'eval_steps_per_second': 10.455, 'epoch': 9.0, 'step': 3141}, {'loss': 0.5854, 'learning_rate': 4.418450827193564e-07, 'epoch': 10.0, 'step': 3490}, {'eval_loss': 0.8230310678482056, 'eval_matthews_correlation': 0.4888339097553538, 'eval_runtime': 14.2779, 'eval_samples_per_second': 83.696, 'eval_steps_per_second': 10.506, 'epoch': 10.0, 'step': 3490}, {'loss': 0.5694, 'learning_rate': 2.209225413596782e-07, 'epoch': 11.0, 'step': 3839}, {'eval_loss': 0.8148431181907654, 'eval_matthews_correlation': 0.45847342180999456, 'eval_runtime': 14.3712, 'eval_samples_per_second': 83.152, 'eval_steps_per_second': 10.438, 'epoch': 11.0, 'step': 3839}, {'loss': 0.5558, 'learning_rate': 0.0, 'epoch': 12.0, 'step': 4188}, {'eval_loss': 0.8184791803359985, 'eval_matthews_correlation': 0.5009729973559511, 'eval_runtime': 14.2947, 'eval_samples_per_second': 83.597, 'eval_steps_per_second': 10.493, 'epoch': 12.0, 'step': 4188}, {'train_runtime': 1760.9942, 'train_samples_per_second': 19.012, 'train_steps_per_second': 2.378, 'total_flos': 8809037225533440.0, 'train_loss': 0.6919248666553807, 'epoch': 12.0, 'step': 4188}, {'eval_loss': 0.7155819535255432, 'eval_matthews_correlation': 0.5230578028869062, 'eval_runtime': 14.3528, 'eval_samples_per_second': 83.259, 'eval_steps_per_second': 10.451, 'epoch': 12.0, 'step': 4188}]\n","<class 'list'>\n","True\n"]}],"source":["from transformers import Trainer\n","from transformers import TrainingArguments\n","#learning_rate = 5e-05\n","batch_size = 8\n","#eval_batch_size = 4\n","seed = 40\n","#optimizer = Adam \n","#with betas=(0.9,0.999) and epsilon=1e-08\n","adam_beta1 = 0.9\n","adam_beta2 =0.999\n","lr_scheduler_type = \"linear\"\n","num_epochs = 15\n","#args = TrainingArguments(\"test_trainer\",report_to=\"wandb\" ,logging_strategy = \"epoch\",evaluation_strategy=\"epoch\",learning_rate = learning_rate,num_train_epochs = num_epochs,lr_scheduler_type =lr_scheduler_type, adam_beta1 = adam_beta1,adam_beta2 =adam_beta2  )\n","\n","args = TrainingArguments(\n","    #'/content/drive/MyDrive/fyp/fyp2/model/model2-supervised/' + f\"{model_name}-finetuned-\",\n","    #'/content/' + f\"{model_name}-finetuned-\",\n","    out,\n","    #report_to=\"wandb\",\n","    overwrite_output_dir = True,\n","    logging_dir = out,\n","    evaluation_strategy = \"epoch\",\n","    logging_strategy = \"epoch\",\n","    #save_strategy = \"NO\",\n","    learning_rate=4.5682e-5,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    num_train_epochs=epoch,\n","    weight_decay=0.01,\n","    metric_for_best_model='matthews_correlation',\n","    save_total_limit = 2,\n","    save_strategy = \"epoch\",\n","    load_best_model_at_end = True,\n","    seed = 40\n","    #push_to_hub=True,\n",")\n","\n","args = TrainingArguments(\n","      #'/content/drive/MyDrive/fyp/fyp2/model/model2-supervised/' + f\"{model_name}-finetuned-\",\n","      #'/content/' + f\"{model_name}-finetuned-\",\n","      out,\n","      #report_to=\"wandb\",\n","      overwrite_output_dir = True,\n","      logging_dir = out,\n","      evaluation_strategy = \"epoch\",\n","      logging_strategy = \"epoch\",\n","      #save_strategy = \"NO\",\n","      learning_rate=2.6510704963161386e-06,\n","      per_device_train_batch_size=batch_size,\n","      per_device_eval_batch_size=batch_size,\n","      num_train_epochs=epoch,\n","      weight_decay=0.01,\n","      metric_for_best_model='matthews_correlation',\n","      save_total_limit = 2,\n","      save_strategy = \"epoch\",\n","      load_best_model_at_end = True,\n","      seed = 18\n","      #push_to_hub=True,\n","  )\n","\n","\n","\n","\n","\n","\n","\n","trainer = Trainer(\n","    model,\n","    args,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")\n","# training\n","train_result = trainer.train() \n","logs = trainer.state.log_history\n","# compute train results\n","metrics = train_result.metrics\n","max_train_samples = len(train_dataset)\n","metrics[\"train_samples\"] = min(max_train_samples, len(train_dataset))\n","\n","# save train results\n","trainer.log_metrics(\"train\", metrics)\n","trainer.save_metrics(\"train\", metrics)\n","\n","# compute evaluation results\n","metrics = trainer.evaluate()\n","max_val_samples = len(eval_dataset)\n","metrics[\"eval_samples\"] = min(max_val_samples, len(eval_dataset))\n","\n","# save evaluation results\n","trainer.log_metrics(\"eval\", metrics)\n","trainer.save_metrics(\"eval\", metrics)\n","\n","import pickle\n","save_logs_dir = out\n","name_logs = \"logs\"\n","\n","my_file = save_logs_dir + \"/\" + name_logs + \".p\"\n","print(\"savint to \" , my_file)\n","\n","pickle.dump( logs, open( my_file, \"wb\" )    ) \n","\n","ld = pickle.load( open( my_file, \"rb\" ) )\n","\n","\n","print(logs)\n","print(logs[2])\n","print(type(logs))\n","\n","print(ld)\n","print(type(ld))\n","print(logs == ld)\n","\n","  #trainer.evaluate()\n","\n"]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","from sklearn.metrics import matthews_corrcoef\n","from transformers import pipeline\n","\n","def huggingface_model_out(directory,tweets):\n","\n","  tokenizer = AutoTokenizer.from_pretrained(directory)\n","  model = AutoModelForSequenceClassification.from_pretrained(directory)\n","  classifier = pipeline(\"sentiment-analysis\", model = model, tokenizer = tokenizer)\n","  df = pd.DataFrame(columns=['label','conf'])\n","  label_list = []\n","  #conf = []\n","  score_ = []\n","  for tweet in tweets:\n","    res = classifier(tweet)[0]\n","    lab = res['label']\n","    #label.append(lab)\n","    #conf.append(res['score'])\n","    if lab == \"Positive\" or lab == \"POS\" or lab == \"LABEL_2\" or lab == \"positive\"  :\n","      label = \"Positive\"\n","      score = 1\n","    elif lab == \"Negative\" or lab == \"NEG\" or lab == \"LABEL_0\" or lab == \"negative\":\n","      label = \"Negative\"\n","      score = -1\n","    elif lab == \"Neutral\" or lab == \"NEU\" or lab == \"LABEL_1\" or lab == \"neutral\":\n","      label = \"Neutral\"\n","      score = 0\n","    else:\n","      print(directory,\" error model\" , label)\n","      score = np.nan\n","    label_list.append(label)  \n","    score_.append(score)\n","\n","  return label_list,score_\n","\n","\n","#model_name = \"svalabs/twitter-xlm-roberta-bitcoin-sentiment\"\n","\n","\n","#tokenizer = AutoTokenizer.from_pretrained(model_name)\n","#model = AutoModelForSequenceClassification.from_pretrained(model_name)\n","#classifier = pipeline(\"sentiment-analysis\", model = model, tokenizer = tokenizer)\n","#res = classifier(df.tweet.values.tolist())\n","\n","#label,conf,score = huggingface_model_out(model_name,data_file[name_of_tweet_column])\n","#result = huggingface_model_out(model_name,df['tweet'])\n","#display(score)\n","#display(label)\n","\n","#display(result)\n","\n","\n","def hugging_face_sentiment_input(df,model_name,name=None,name_of_tweet_column=\"text\"):\n","  if name == None:\n","    name = model_name\n","  label,score = huggingface_model_out(model_name,df[name_of_tweet_column])\n","  df[name + '_score'] = score\n","  df[name + '_sent'] = label\n","  #df[name + '_conf'] = conf\n","  return df\n","\n","\n","def find_metrics(df):\n","  col_names = []\n","  accu = []\n","  matthew =[]\n","  true_col = 'label'\n","  for name in df:\n","    if name.endswith(\"_sent\"):\n","      #df_out[name + \"_accuracy\"] = accuracy_score[df[true],df[name]]\n","      col_names.append(name[:-5])\n","\n","  df_out = pd.DataFrame(columns = col_names)\n","\n","  for name in col_names:\n","    print(name)\n","    true = df[true_col].tolist()\n","    pred = df[name+\"_sent\"].tolist()\n","    #print(true)\n","    accu.append( accuracy_score(true,pred)) \n","    matthew.append( matthews_corrcoef(true,pred) )\n","  #df_out.loc['accuracy'] = accu\n","  df_out.loc[\"MATTHEW'S CORRELATION COEFFICIENT (MCC)\"] = matthew\n","  return df_out.T.sort_values(by=[\"MATTHEW'S CORRELATION COEFFICIENT (MCC)\"])\n","\n","\n","\n","\n","\n","\n","test_path = \"/content/drive/MyDrive/fyp/fyp2/final models and datasets/dataset/dataset_new_with_self_label_final_5.0:3.0:3.0/test_dataset.csv\"\n","df_test = pd.read_csv(test_path)\n","\n","df_test = hugging_face_sentiment_input(df_test,\"/content/temp/checkpoint-3546\")\n","df_metric = find_metrics(df_test)\n","display(df_metric)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":415},"id":"aqQGahm99H1l","executionInfo":{"status":"error","timestamp":1659839320420,"user_tz":-60,"elapsed":1940,"user":{"displayName":"S Rahman","userId":"04000762971548563689"}},"outputId":"9df8f23e-64b8-46f8-98ad-3c8b60dce6bd"},"execution_count":13,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-b0d25efb7f1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhugging_face_sentiment_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"/content/temp/checkpoint-3546\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0mdf_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_metric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-b0d25efb7f1d>\u001b[0m in \u001b[0;36mhugging_face_sentiment_input\u001b[0;34m(df, model_name, name, name_of_tweet_column)\u001b[0m\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m   \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhuggingface_model_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname_of_tweet_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m   \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m   \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_sent'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-b0d25efb7f1d>\u001b[0m in \u001b[0;36mhuggingface_model_out\u001b[0;34m(directory, tweets)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhuggingface_model_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sentiment-analysis\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;31m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m         \u001b[0mtokenizer_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tokenizer_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0mconfig_tokenizer_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tokenizer_class\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0mtokenizer_auto_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mget_tokenizer_config\u001b[0;34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, **kwargs)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m         \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m     )\n\u001b[1;32m    403\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresolved_config_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mget_file_from_repo\u001b[0;34m(path_or_repo, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only)\u001b[0m\n\u001b[1;32m    709\u001b[0m             \u001b[0mresume_download\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_download\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m             \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m         )\n\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0muser_agent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_agent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m             \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m         )\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m    561\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                     raise ValueError(\n\u001b[0;32m--> 563\u001b[0;31m                         \u001b[0;34m\"Connection error, and we cannot find the requested files in the cached path.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m                         \u001b[0;34m\" Please try again or make sure your Internet connection is on.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m                     )\n","\u001b[0;31mValueError\u001b[0m: Connection error, and we cannot find the requested files in the cached path. Please try again or make sure your Internet connection is on."]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-84QX-hcdTAm","executionInfo":{"status":"aborted","timestamp":1659839320412,"user_tz":-60,"elapsed":43,"user":{"displayName":"S Rahman","userId":"04000762971548563689"}}},"outputs":[],"source":["#!kill -9 -1"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"finetuner-sentiment.ipynb","provenance":[],"mount_file_id":"1BUoiPdIj_YosKbOIoOiNQnE0VXVErHUg","authorship_tag":"ABX9TyNJA36ArP3FXOq2qw7riha4"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"a128df2e7bc74089952d564327295a2c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c3da4af1933241fca873e986133d6ce7","IPY_MODEL_ae0878c1f7da49fdb302e2f4cbf6099d","IPY_MODEL_9da02d789a5549139b9fef16d7e71f87"],"layout":"IPY_MODEL_acf390c9cfed43dc84d8f74080ba3c04"}},"c3da4af1933241fca873e986133d6ce7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_186dfca8c19a4104bb2acb8607704f48","placeholder":"‚Äã","style":"IPY_MODEL_d6e45edb554040ea8bf90f1832304fb1","value":"100%"}},"ae0878c1f7da49fdb302e2f4cbf6099d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_eeb247ecde1f4e4cafb6fa5ecffd5932","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4476fe01f8a34b4ba36ff67238974b10","value":3}},"9da02d789a5549139b9fef16d7e71f87":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_74753b649c7b43c7a8d4edc640b79b9a","placeholder":"‚Äã","style":"IPY_MODEL_4df0837afa994b53a60596d81f7529bd","value":" 3/3 [00:00&lt;00:00,  6.26ba/s]"}},"acf390c9cfed43dc84d8f74080ba3c04":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"186dfca8c19a4104bb2acb8607704f48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6e45edb554040ea8bf90f1832304fb1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eeb247ecde1f4e4cafb6fa5ecffd5932":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4476fe01f8a34b4ba36ff67238974b10":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"74753b649c7b43c7a8d4edc640b79b9a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4df0837afa994b53a60596d81f7529bd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"daba5528bc964e7da2b988db7dee6e4e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_825b03ef0491471ba5df15beb464e9b0","IPY_MODEL_70b4c66e41d14c1e8f3827636d12b440","IPY_MODEL_30c00b93f34849d3a39ef00312b676f4"],"layout":"IPY_MODEL_6e29591aaa334273a4922399185e6633"}},"825b03ef0491471ba5df15beb464e9b0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7a1be35f747b425fb78d12e802f3e8cf","placeholder":"‚Äã","style":"IPY_MODEL_8799f18802aa4c309f5383ae3acab966","value":"100%"}},"70b4c66e41d14c1e8f3827636d12b440":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fafb8310b8ff4d5e9ce6e3c7ac8d5d4a","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_262dbffa48fe47ac838ae2edafcfc81c","value":2}},"30c00b93f34849d3a39ef00312b676f4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e5106a321ce41e8a1d331b212fcdb3a","placeholder":"‚Äã","style":"IPY_MODEL_5a42086c962f45eda435ae37ffeefe5f","value":" 2/2 [00:00&lt;00:00,  5.27ba/s]"}},"6e29591aaa334273a4922399185e6633":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a1be35f747b425fb78d12e802f3e8cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8799f18802aa4c309f5383ae3acab966":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fafb8310b8ff4d5e9ce6e3c7ac8d5d4a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"262dbffa48fe47ac838ae2edafcfc81c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6e5106a321ce41e8a1d331b212fcdb3a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a42086c962f45eda435ae37ffeefe5f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}